{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIs Lab\n",
    "In this lab we will practice using APIs to retrieve and store data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports at the top\n",
    "import json\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Get Data From Sheetsu\n",
    "\n",
    "[Sheetsu](https://sheetsu.com/) is an online service that allows you to access any Google spreadsheet from an API. This can be a very powerful way to share a dataset with colleagues as well as to create a mini centralized data storage, that is simpler to edit than a database.\n",
    "\n",
    "A Google Spreadsheet with Wine data can be found [here]().\n",
    "\n",
    "It can be accessed through sheetsu API at this endpoint: https://sheetsu.com/apis/v1.0/dab55afd\n",
    "\n",
    "Questions:\n",
    "\n",
    "1. Use the requests library to access the document. Inspect the response text. What kind of data is it?\n",
    "> Answer: it's a JSON string\n",
    "- Check the status code of the response object. What code is it?\n",
    "> 200\n",
    "- Use the appropriate libraries and read functions to read the response into a Pandas Dataframe\n",
    "> Possible answers include: pd.read_json and json.loads + pd.Dataframe\n",
    "- Once you've imported the data into a dataframe, check the value of the 5th line: what's the price?\n",
    "> 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! application/json;charset=UTF-8\n"
     ]
    }
   ],
   "source": [
    "my_url = \"https://sheetsu.com/apis/v1.0/dab55afd\"\n",
    "r = requests.get(my_url)\n",
    "if r.status_code == 200:\n",
    "    print(\"Success! %s\" % r.headers['content-type'])\n",
    "    content = r.json()\n",
    "else:\n",
    "    print(\"Connection failed, error %d\" % r.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Color</th>\n",
       "      <th>Consumed In</th>\n",
       "      <th>Country</th>\n",
       "      <th>Grape</th>\n",
       "      <th>Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Region</th>\n",
       "      <th>Score</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Vinyard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W</td>\n",
       "      <td>2015</td>\n",
       "      <td>Portugal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Portugal</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>Vinho Verde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W</td>\n",
       "      <td>2015</td>\n",
       "      <td>France</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>17.8</td>\n",
       "      <td>France</td>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>Peyruchet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W</td>\n",
       "      <td>2015</td>\n",
       "      <td>Oregon</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>20</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>Abacela</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W</td>\n",
       "      <td>2015</td>\n",
       "      <td>Spain</td>\n",
       "      <td>chardonay</td>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>Spain</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2012</td>\n",
       "      <td>Ochoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R</td>\n",
       "      <td>2015</td>\n",
       "      <td>US</td>\n",
       "      <td>chiraz, cab</td>\n",
       "      <td>Spice Trader</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>2012</td>\n",
       "      <td>Heartland</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Color Consumed In   Country        Grape          Name Price    Region  \\\n",
       "0     W        2015  Portugal                                   Portugal   \n",
       "1     W        2015    France                             17.8    France   \n",
       "2     W        2015    Oregon                               20    Oregon   \n",
       "3     W        2015     Spain    chardonay                   7     Spain   \n",
       "4     R        2015        US  chiraz, cab  Spice Trader     6             \n",
       "\n",
       "  Score Vintage      Vinyard  \n",
       "0     4    2013  Vinho Verde  \n",
       "1     3    2013    Peyruchet  \n",
       "2     3    2013      Abacela  \n",
       "3   2.5    2012        Ochoa  \n",
       "4     3    2012    Heartland  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df = pd.DataFrame(content)\n",
    "wine_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Post Data to Sheetsu\n",
    "Now that we've learned how to read data, it'd be great if we could also write data. For this we will need to use a _POST_ request.\n",
    "\n",
    "1. Use the post command to add the following data to the spreadsheet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201\n",
      "{\"Score\":\"10\",\"Grape\":\"Pinot Noir\",\"Name\":\"Chateau Gregory\",\"Vintage\":\"1978\",\"Color\":\"R\",\"Country\":\"FR\",\"Region\":\"Vosges\",\"Vinyard\":\"Perso\",\"Price\":\"2000\",\"Consumed In\":\"\"}\n"
     ]
    }
   ],
   "source": [
    "post_data = {\n",
    "'Grape' : 'Pinot Noir'\n",
    ", 'Name' : 'Chateau Gregory'\n",
    ", 'Color' : 'R'\n",
    ", 'Country' : 'FR'\n",
    ", 'Region' : 'Vosges'\n",
    ", 'Vinyard' : 'Perso'\n",
    ", 'Score' : '10'\n",
    ", 'Consumed In' : ''\n",
    ", 'Vintage' : '1978'\n",
    ", 'Price' : '2000'\n",
    "}\n",
    "r = requests.post(my_url,data = post_data)\n",
    "print(r.status_code)\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection failed, error 201\n"
     ]
    }
   ],
   "source": [
    "if r.status_code == 200:\n",
    "    print(\"Success! %s\" % r.headers['content-type'])\n",
    "    content = r.json()\n",
    "else:\n",
    "    print(\"Connection failed, error %d\" % r.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What status did you get? How can you check that you actually added the data correctly?\n",
    "- In this exercise, your classmates are adding data to the same spreadsheet. What happens because of this? Is it a problem? How could you mitigate it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection failed, error 201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(291, 10)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Data munging\n",
    "\n",
    "Get back to the dataframe you've created in the beginning. Let's do some data munging:\n",
    "\n",
    "1. Search for missing data\n",
    "    - Is there any missing data? How do you deal with it?\n",
    "    - Is there any data you can just remove?\n",
    "    - Are the data types appropriate?\n",
    "- Summarize the data \n",
    "    - Try using describe, min, max, mean, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection failed, error 500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(294, 10)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = requests.get(my_url)\n",
    "if r.status_code == 200:\n",
    "    print(\"Success! %s\" % r.headers['content-type'])\n",
    "    content = r.json()\n",
    "else:\n",
    "    print(\"Connection failed, error %d\" % r.status_code)\n",
    "wine_df = pd.DataFrame(content)\n",
    "wine_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wine_df = wine_df.replace('',np.nan)\n",
    "t_wine_df = wine_df.drop(wine_df.index[90:95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: Over 9000",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-323307c1cb96>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mt_wine_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Score'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Price'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt_wine_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Score'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Price'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mt_wine_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, raise_on_error, **kwargs)\u001b[0m\n\u001b[0;32m   2948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2949\u001b[0m         mgr = self._data.astype(dtype=dtype, copy=copy,\n\u001b[1;32m-> 2950\u001b[1;33m                                 raise_on_error=raise_on_error, **kwargs)\n\u001b[0m\u001b[0;32m   2951\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmgr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2952\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[0;32m   2936\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2937\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2938\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'astype'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2940\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, axes, filter, do_integrity_check, consolidate, raw, **kwargs)\u001b[0m\n\u001b[0;32m   2888\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2889\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mgr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2890\u001b[1;33m             \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2891\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, raise_on_error, values, **kwargs)\u001b[0m\n\u001b[0;32m    432\u001b[0m                **kwargs):\n\u001b[0;32m    433\u001b[0m         return self._astype(dtype, copy=copy, raise_on_error=raise_on_error,\n\u001b[1;32m--> 434\u001b[1;33m                             values=values, **kwargs)\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m     def _astype(self, dtype, copy=False, raise_on_error=True, values=None,\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36m_astype\u001b[1;34m(self, dtype, copy, raise_on_error, values, klass, mgr, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m                 \u001b[1;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_astype_nansafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\core\\common.pyc\u001b[0m in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy)\u001b[0m\n\u001b[0;32m   1918\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1920\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1921\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: Over 9000"
     ]
    }
   ],
   "source": [
    "t_wine_df[['Score','Price']] = t_wine_df[['Score','Price']].astype(float)\n",
    "t_wine_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Color</th>\n",
       "      <th>Consumed In</th>\n",
       "      <th>Country</th>\n",
       "      <th>Grape</th>\n",
       "      <th>Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Region</th>\n",
       "      <th>Score</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Vinyard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>294</td>\n",
       "      <td>293</td>\n",
       "      <td>292</td>\n",
       "      <td>26</td>\n",
       "      <td>285</td>\n",
       "      <td>288</td>\n",
       "      <td>293</td>\n",
       "      <td>293</td>\n",
       "      <td>294</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>54</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>R</td>\n",
       "      <td>2015</td>\n",
       "      <td>US</td>\n",
       "      <td>sauvignon blanc</td>\n",
       "      <td>My wonderful wine</td>\n",
       "      <td>200</td>\n",
       "      <td>Sonoma</td>\n",
       "      <td>10</td>\n",
       "      <td>1973</td>\n",
       "      <td>Top of the line wine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>272</td>\n",
       "      <td>263</td>\n",
       "      <td>266</td>\n",
       "      <td>4</td>\n",
       "      <td>212</td>\n",
       "      <td>253</td>\n",
       "      <td>250</td>\n",
       "      <td>255</td>\n",
       "      <td>251</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Color Consumed In Country            Grape               Name Price  \\\n",
       "count    294         293     292               26                285   288   \n",
       "unique     7          14      15               20                 54    26   \n",
       "top        R        2015      US  sauvignon blanc  My wonderful wine   200   \n",
       "freq     272         263     266                4                212   253   \n",
       "\n",
       "        Region Score Vintage               Vinyard  \n",
       "count      293   293     294                    39  \n",
       "unique      28    14      14                    34  \n",
       "top     Sonoma    10    1973  Top of the line wine  \n",
       "freq       250   255     251                     3  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Feature Extraction\n",
    "\n",
    "We would like to use a regression tree to predict the score of a wine. In order to do that, we first need to select and engineer appropriate features.\n",
    "\n",
    "- Set the target to be the Score column, drop the rows with no score\n",
    "- Use pd.get_dummies to create dummy features for all the text columns\n",
    "- Fill the nan values in the numerical columns, using an appropriate method\n",
    "- Train a Decision tree regressor on the Score, using a train test split:\n",
    "        X_train, X_test, y_train, y_test, = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "- Plot the test values, the predicted values and the residuals\n",
    "- Calculate R^2 score\n",
    "- Discuss your findings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: IMDB Movies\n",
    "\n",
    "Sometimes an API doesn't provide all the information we would like to get and we need to be creative.\n",
    "Here we will use a combination of scraping and API calls to investigate the ratings and gross earnings of famous movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5.a Get top movies\n",
    "\n",
    "The Internet Movie Database contains data about movies. Unfortunately it does not have a public API.\n",
    "\n",
    "The page http://www.imdb.com/chart/top contains the list of the top 250 movies of all times. Retrieve the page using the requests library and then parse the html to obtain a list of the `movie_ids` for these movies. You can parse it with regular expression or using a library like `BeautifulSoup`.\n",
    "\n",
    "**Hint:** movie_ids look like this: `tt2582802`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "url = \"http://www.imdb.com/chart/top\"\n",
    "r = urllib.urlopen(url).read()\n",
    "soup = BeautifulSoup(r,\"lxml\")\n",
    "res = soup.findAll(\"td\",class_=\"titleColumn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = []\n",
    "for i in range(len(res)):\n",
    "    movies.append(res[i].a.contents[0])\n",
    "len(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.b Get top movies data\n",
    "\n",
    "Although the Internet Movie Database does not have a public API, an open API exists at http://www.omdbapi.com.\n",
    "\n",
    "Use this API to retrieve information about each of the 250 movies you have extracted in the previous step.\n",
    "- Check the documentation of omdbapi.com to learn how to request movie data by id\n",
    "- Define a function that returns a python object with all the information for a given id\n",
    "- Iterate on all the IDs and store the results in a list of such objects\n",
    "- Create a Pandas Dataframe from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.c Get gross data\n",
    "\n",
    "The OMDB API is great, but it does not provide information about Gross Revenue of the movie. We'll revert back to scraping for this.\n",
    "\n",
    "- Write a function that retrieves the gross revenue from the entry page at imdb.com\n",
    "- The function should handle the exception of when the page doesn't report gross revenue\n",
    "- Retrieve the gross revenue for each movie and store it in a separate dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.d Data munging\n",
    "\n",
    "- Now that you have movie information and gross revenue information, let's clean the two datasets.\n",
    "- Check if there are null values. Be careful they may appear to be valid strings.\n",
    "- Convert the columns to the appropriate formats. In particular handle:\n",
    "    - Released\n",
    "    - Runtime\n",
    "    - year\n",
    "    - imdbRating\n",
    "    - imdbVotes\n",
    "- Merge the data from the two datasets into a single one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.d Text vectorization\n",
    "\n",
    "There are several columns in the data that contain a comma separated list of items, for example the Genre column and the Actors column. Let's transform those to binary columns using the count vectorizer from scikit learn.\n",
    "\n",
    "Append these columns to the merged dataframe.\n",
    "\n",
    "**Hint:** In order to get the actors name right, you'll have to modify the `token_pattern` in the `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus:\n",
    "\n",
    "- What are the top 10 grossing movies?\n",
    "- Who are the 10 actors that appear in the most movies?\n",
    "- What's the average grossing of the movies in which each of these actors appear?\n",
    "- What genre is the oldest movie?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
