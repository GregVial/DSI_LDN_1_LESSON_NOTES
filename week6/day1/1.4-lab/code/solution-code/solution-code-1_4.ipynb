{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIs Lab\n",
    "In this lab we will practice using APIs to retrieve and store data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports at the top\n",
    "import json\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Get Data From Sheetsu\n",
    "\n",
    "[Sheetsu](https://sheetsu.com/) is an online service that allows you to access any Google spreadsheet from an API. This can be a very powerful way to share a dataset with colleagues as well as to create a mini centralized data storage, that is simpler to edit than a database.\n",
    "\n",
    "A Google Spreadsheet with Wine data can be found [here](https://docs.google.com/spreadsheets/d/1mZ3Otr5AV4v8WwvLOAvWf3VLxDa-IeJ1AVTEuavJqeo/).\n",
    "\n",
    "It can be accessed through sheetsu API at this endpoint: https://sheetsu.com/apis/v1.0/dab55afd\n",
    "\n",
    "Questions:\n",
    "\n",
    "1. Use the requests library to access the document. Inspect the response text. What kind of data is it?\n",
    "> Answer: it's a json string\n",
    "- Check the status code of the response object. What code is it?\n",
    "> 200\n",
    "- Use the appropriate libraries and read functions to read the response into a Pandas Dataframe\n",
    "> Possible answers include: pd.read_json and json.loads + pd.Dataframe\n",
    "- Once you've imported the data into a dataframe, check the value of the 5th line: what's the price?\n",
    "> 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can either post or get info from this API\n",
    "api_base_url = 'https://sheetsu.com/apis/v1.0/dab55afd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# What kind of data is this returning?\n",
    "api_response = requests.get(api_base_url)\n",
    "api_response.text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reponse = json.loads(api_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(reponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reponse[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "api_response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets read the data into a DataFrame!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wine_df = pd.DataFrame(reponse)\n",
    "wine_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas has great functions. We could just do it this way\n",
    "\n",
    "This sometimes works, but the data may need adjusting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wine_df = pd.read_json(api_response.text)\n",
    "wine_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Post Data to Sheetsu\n",
    "Now that we've learned how to read data, it'd be great if we could also write data. For this we will need to use a _POST_ request.\n",
    "\n",
    "1. Use the post command to add the following data to the spreadsheet:\n",
    "- What status did you get? How can you check that you actually added the data correctly?\n",
    "> Answer: send a get request and check the last line added\n",
    "- In this exercise, your classmates are adding data to the same spreadsheet. What happens because of this? Is it a problem? How could you mitigate it?\n",
    "> There will be many duplicate lines on the spreadsheet. One way to mitigate this would be through permission, another would be to insert at a specific position, so that the line is overwritten at each time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "post_data = {\n",
    "'Grape' : ''\n",
    ", 'Name' : 'My wonderful wine'\n",
    ", 'Color' : 'R'\n",
    ", 'Country' : 'US'\n",
    ", 'Region' : 'Sonoma'\n",
    ", 'Vinyard' : ''\n",
    ", 'Score' : '10'\n",
    ", 'Consumed In' : '2015'\n",
    ", 'Vintage' : '1973'\n",
    ", 'Price' : '200'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "requests.post(api_base_url, data=post_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Data munging\n",
    "\n",
    "Get back to the dataframe you've created in the beginning. Let's do some data munging:\n",
    "\n",
    "1. Search for missing data\n",
    "    - Is there any missing data? How do you deal with it?\n",
    "    - Is there any data you can just remove?\n",
    "    - Are the data types appropriate?\n",
    "- Summarize the data \n",
    "    - Try using describe, min, max, mean, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wine_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wine_df = wine_df.replace('', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wine_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wine_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wine_df[['Score', 'Price']] = wine_df[['Score', 'Price']].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wine_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wine_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Feature Extraction\n",
    "\n",
    "We would like to use a regression tree to predict the score of a wine. In order to do that, we first need to select and engineer appropriate features.\n",
    "\n",
    "- Set the target to be the Score column, drop the rows with no score\n",
    "- Use pd.get_dummies to create dummy features for all the text columns\n",
    "- Fill the nan values in the numerical columns, using an appropriate method\n",
    "- Train a Decision tree regressor on the Score, using a train test split:\n",
    "        X_train, X_test, y_train, y_test, = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "- Plot the test values, the predicted values and the residuals\n",
    "- Calculate R^2 score\n",
    "- Discuss your findings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dropped = wine_df[~wine_df['Score'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = dropped['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numerical = ['Consumed In', 'Price', 'Vintage']\n",
    "dummies = [c for c in dropped.columns if c not in numerical + ['Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = dropped[numerical].join(pd.get_dummies(dropped[dummies]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = make_pipeline(Imputer(),\n",
    "                   DecisionTreeRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(y_test.values, 'o')\n",
    "plt.plot(y_pred, 'o')\n",
    "plt.legend(['actual', 'predicted'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resid = y_pred - y_test.values\n",
    "plt.plot(resid, 'o-')\n",
    "plt.axhline(resid.mean(), color = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Discussion\n",
    "The regression score is very bad and the predicted values do not seem to reproduce the expected values. This is probably due to 2 factors:\n",
    "- too few data points to actually use machine learning\n",
    "- features are probably not indicative of the score\n",
    "Discuss with students here about the importance of not applying a ML model blindly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: IMDB Movies\n",
    "\n",
    "Sometimes an API doesn't provide all the information we would like to get and we need to be creative.\n",
    "Here we will use a combination of scraping and API calls to investigate the ratings and gross earnings of famous movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5.a Get top movies\n",
    "\n",
    "The Internet Movie Database contains data about movies. Unfortunately it does not have a public API.\n",
    "\n",
    "The page http://www.imdb.com/chart/top contains the list of the top 250 movies of all times. Retrieve the page using the requests library and then parse the html to obtain a list of the `movie_ids` for these movies. You can parse it with regular expression or using a library like `BeautifulSoup`.\n",
    "\n",
    "**Hint:** movie_ids look like this: `tt2582802`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_top_250():\n",
    "    response = requests.get('http://www.imdb.com/chart/top')\n",
    "    html = response.text\n",
    "    entries = re.findall(\"<a href.*?/title/(.*?)/\", html) #Wrong regex\n",
    "    return list(set(entries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "entries = get_top_250()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entries[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.b Get top movies data\n",
    "\n",
    "Although the Internet Movie Database does not have a public API, an open API exists at http://www.omdbapi.com.\n",
    "\n",
    "Use this API to retrieve information about each of the 250 movies you have extracted in the previous step.\n",
    "1. Check the documentation of omdbapi.com to learn how to request movie data by id\n",
    "- Define a function that returns a python object with all the information for a given id\n",
    "- Iterate on all the IDs and store the results in a list of such objects\n",
    "- Create a Pandas Dataframe from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_entry(entry):\n",
    "    res = requests.get('http://www.omdbapi.com/?i='+entry)\n",
    "    if res.status_code != 200:\n",
    "        print entry, res.status_code\n",
    "    else:\n",
    "        print '.',\n",
    "    try:\n",
    "        j = json.loads(res.text)\n",
    "    except ValueError:\n",
    "        j = None\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entries_dict_list = [get_entry(e) for e in entries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(entries_dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(entries_dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.c Get gross data\n",
    "\n",
    "The OMDB API is great, but it does not provide information about Gross Revenue of the movie. We'll revert back to scraping for this.\n",
    "\n",
    "1. Write a function that retrieves the gross revenue from the entry page at imdb.com\n",
    "- The function should handle the exception of when the page doesn't report gross revenue\n",
    "- Retrieve the gross revenue for each movie and store it in a separate dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_gross(entry):\n",
    "    response = requests.get('http://www.imdb.com/title/'+entry)\n",
    "    html = response.text\n",
    "    try:\n",
    "        gross_list = re.findall(\"Gross:</h4>[ ]*\\$([^ ]*)\", html)\n",
    "        gross = int(gross_list[0].replace(',', ''))\n",
    "        print '.',\n",
    "        return gross\n",
    "    except Exception as ex:\n",
    "        print\n",
    "        print ex, entry, response.status_code\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grosses = [(e, get_gross(e)) for e in entries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(grosses, columns=['imdbID', 'Gross'])\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.d Data munging\n",
    "\n",
    "1. Now that you have movie information and gross revenue information, let's clean the two datasets.\n",
    "- Check if there are null values. Be careful they may appear to be valid strings.\n",
    "- Convert the columns to the appropriate formats. In particular handle:\n",
    "    - Released\n",
    "    - Runtime\n",
    "    - year\n",
    "    - imdbRating\n",
    "    - imdbVotes\n",
    "- Merge the data from the two datasets into a single one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.replace('N/A', np.nan)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.Released = pd.to_datetime(df.Released)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def intminutes(x):\n",
    "    y = x.replace('min', '').strip()\n",
    "    return int(y)\n",
    "\n",
    "df.Runtime = df.Runtime.apply(intminutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.Year = df.Year.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.imdbRating = df.imdbRating.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def intvotes(x):\n",
    "    y = x.replace(',', '').strip()\n",
    "    return int(y)\n",
    "df.imdbVotes = df.imdbVotes.apply(intvotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.merge(df, df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.d Text vectorization\n",
    "\n",
    "There are several columns in the data that contain a comma separated list of items, for example the Genre column and the Actors column. Let's transform those to binary columns using the count vectorizer from scikit learn.\n",
    "\n",
    "Append these columns to the merged dataframe.\n",
    "\n",
    "**Hint:** In order to get the actors name right, you'll have to modify the `token_pattern` in the `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "data = cv.fit_transform(df.Genre).todense()\n",
    "columns = ['genre_'+c for c in cv.get_feature_names()]\n",
    "genredf = pd.DataFrame(data, columns=columns)\n",
    "genredf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df, genredf], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(token_pattern=u'(?u)\\\\w+\\.?\\\\w?\\.? \\\\w+')\n",
    "data = cv.fit_transform(df.Actors).todense()\n",
    "columns = ['actor: '+c for c in cv.get_feature_names()]\n",
    "actorsdf = pd.DataFrame(data, columns=columns)\n",
    "actorsdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.Actors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actorsdf.loc[0,actorsdf.iloc[0] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df, actorsdf], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus:\n",
    "\n",
    "1. What are the top 10 grossing movies?\n",
    "- Who are the 10 actors that appear in the most movies?\n",
    "- What's the average grossing of the movies in which each of these actors appear?\n",
    "- What genre is the oldest movie?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[['Title','Gross', 'Genre']].sort_values('Gross', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actorcols = actorsdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topactors = actorsdf.sum().sort_values(ascending = False).head(10)\n",
    "topactors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "means = [df.loc[df[actor]==1,'Gross'].mean() for actor in topactors.index]\n",
    "means = pd.Series(means, index = topactors.index)\n",
    "means.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.sort_values('Released')[['Genre', 'Title', 'Released', 'Gross']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
