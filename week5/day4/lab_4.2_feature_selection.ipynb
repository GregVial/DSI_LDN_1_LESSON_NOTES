{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection Methods in sklearn Lab\n",
    "\n",
    "In this lab we will explore feature selection on the Titanic Dataset. First of all let's load a few things:\n",
    "\n",
    "- The training set from lab 2.3\n",
    "- The union we have saved in lab 2.3\n",
    "\n",
    "\n",
    "You can load the titanic data as follows:\n",
    "\n",
    "    psql -h dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com -p 5432 -U dsi_student titanic\n",
    "    password: gastudents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://dsi_student:gastudents@dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com/titanic')\n",
    "\n",
    "# We will pull in the Titanic data as before\n",
    "df = pd.read_sql('SELECT * FROM train', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  PassengerId  Survived  Pclass  \\\n",
       "0      0            1         0       3   \n",
       "1      1            2         1       1   \n",
       "2      2            3         1       3   \n",
       "3      3            4         1       1   \n",
       "4      4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500  None        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250  None        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500  None        S  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.5924806 ,  0.        ,  1.        ,  0.        ,  1.        ,\n",
       "        1.        , -0.50244517])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gzip\n",
    "import dill\n",
    "\n",
    "# I've set up a preset union object here, from lab 2.3. You can complete the lab with this but you may find it more\n",
    "# satisfying to load the version that you made in that lab (and hopefully saved as union.dill.gz)\n",
    "with gzip.open('union_preset.dill.gz') as fin:\n",
    "    union = dill.load(fin)\n",
    "    \n",
    "X = df[[u'Pclass', u'Sex', u'Age', u'SibSp', u'Parch', u'Fare', u'Embarked']]\n",
    "y = df[u'Survived']\n",
    "\n",
    "X_transf = union.fit_transform(X)\n",
    "X_transf[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1 Column names\n",
    "\n",
    "The column names have become lost along the way. We can manually add them back in:\n",
    "\n",
    "`union = make_union(age_pipe, one_hot_pipe, gender_pipe, fare_pipe)`\n",
    "\n",
    "- age_pipe => 'scaled_age'\n",
    "- one_hot_pipe => 'Pclass_2', 'Pclass_3', 'Embarked_Q', 'Embarked_S'\n",
    "- gender_pipe => 'male'\n",
    "- fare_pipe => 'scaled_fare'\n",
    "\n",
    "We need to:\n",
    "\n",
    "1. Create a new pandas dataframe `Xt` with the appropriate column names and fill it with the `X_transf` data.\n",
    "2. Notice that we discard the columns: u'SibSp', u'Parch', that is unless you covered this part in lab 2.3 (this was an optional bonus). So we ignore them in this analysis, unless you dealt with them there in which case do keep using them.\n",
    "3. The order of columns should match the order you place the pipelines in the union; I have added the code I used above from lab 2.3 which was used to make the union_preset.dill.gz file. If you are importing your own union object you may wish to verify the code you used by reopening the notebook from lab 2.3.\n",
    "\n",
    "**Check:** are you clear on why we do not have a dummy variable for Pclass_1 or Embarked_C?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_age</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>male</th>\n",
       "      <th>scaled_fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.592481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.502445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.638789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.786845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   scaled_age  Pclass_2  Pclass_3  Embarked_Q  Embarked_S  male  scaled_fare\n",
       "0   -0.592481       0.0       1.0         0.0         1.0   1.0    -0.502445\n",
       "1    0.638789       0.0       0.0         0.0         0.0   0.0     0.786845"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = ['scaled_age','Pclass_2','Pclass_3','Embarked_Q','Embarked_S','male','scaled_fare']\n",
    "Xt = pd.DataFrame(X_transf,columns=col_names)\n",
    "Xt.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature selection\n",
    "\n",
    "Let's use the `SelectKBest` method in scikit learn to see which are the top 5 features (out of how many?). We will use the f test for classification method that we discussed in the lecture (this is actually the default but we import it just to be explicit about our methodology, this is particularly important for this approach because it can still give\n",
    "results if you apply the test for a countinous output rather than a classification output - but this would be meaningless, hence always have a think about which test you are actually applying with these methods).\n",
    "\n",
    "- What are the top 5 features for `Xt`?\n",
    "- Check the methods associated with SelectKBest to see how to interact with it and return the columns of interest (eg get_support returns booleans you can use for indexing the dataframe)\n",
    "\n",
    "=> store them in a variable called `kbest_columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True  True False  True  True  True]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Check the documentation for SelectKBest, note that the f_classif\n",
    "# is passed as an argument itself (i.e. not as a string)\n",
    "selector = SelectKBest(k=5).fit(Xt,y)\n",
    "print(selector.get_support())\n",
    "kbest_columns = selector.get_support(indices=True)\n",
    "kbest_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.72170837e-02   5.29365528e-03   5.51028100e-23   9.13353235e-01\n",
      "   3.03611106e-06   1.40606613e-69   6.12018934e-15]\n",
      "Index([u'scaled_age', u'Pclass_2', u'Pclass_3', u'Embarked_Q', u'Embarked_S',\n",
      "       u'male', u'scaled_fare'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# If you manage the above, you might be a bit unclear about how it has selected these\n",
    "# top five. If you call selector.pvalues_ you can return the p value results of the\n",
    "# comparisons of the inputs to see which are the more significant\n",
    "\n",
    "print(selector.pvalues_)\n",
    "print(Xt.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Recursive Feature Elimination\n",
    "\n",
    "`Scikit Learn` also offers recursive feature elimination as a class named `RFE`. Use it in combination with a logistic regression model to see what features would be kept with this method.\n",
    "\n",
    "=> store them in a variable called `rfecv_columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "  n_features_to_select=None, step=1, verbose=0)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Check the documentation for RFE. You can first instantiate the logistic \n",
    "# regression object, then pass it as an argument to the RFE\n",
    "logreg = LogisticRegression()\n",
    "selector = RFE(logreg)\n",
    "selector.fit(Xt,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True  True False False  True False]\n",
      "[0, 1, 1, 0, 0, 1, 0]\n",
      "[3 1 1 5 2 1 4]\n"
     ]
    }
   ],
   "source": [
    "# These methods can reveal more and also can be used for boolean indexing of the features\n",
    "rfecv_columns = selector.support_\n",
    "print(rfecv_columns)\n",
    "rfecv_columns = [1 if _ else 0 for _ in rfecv_columns]\n",
    "print(rfecv_columns)\n",
    "print(selector.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFECV(cv=5,\n",
       "   estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "   n_jobs=1, scoring=None, step=1, verbose=0)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bonus - also try from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import RFECV\n",
    "selector2 = RFECV(logreg,cv=5)\n",
    "selector2.fit(Xt,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True False  True  True  True]\n",
      "[1 1 1 2 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(selector2.support_)\n",
    "print(selector2.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Logistic regression coefficients\n",
    "\n",
    "Let's see what we get with the Logistic Regression coefficients.\n",
    "\n",
    "- Create a logistic regression model\n",
    "- Perform grid search over penalty type and C strength in order to find the best parameters\n",
    "- Sort the logistic regression coefficients by absolute value. Do the top 5 correspond to those above? They may not because these selection methods are distinct. So it's up to you to decide on the best approach.\n",
    "\n",
    "=> choose which ones you would keep and store them in a variable called `lr_columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100.0, 'penalty': 'l1'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "logreg = LogisticRegression()\n",
    "C_vals = [0.0001, 0.001, 0.01, 0.1, 0.5, 0.75, 1.0, 2.5, 5.0, 10.0, 100.0, 1000.0]\n",
    "penalties = ['l1','l2']\n",
    "gs = GridSearchCV(logreg, {'penalty':penalties, 'C':C_vals}, cv=5, scoring='accuracy')\n",
    "gs.fit(Xt,y)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This method can tell you which of the model instances performed best\n",
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 3, 2, 7, 4, 1, 6]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_logreg = LogisticRegression(C=gs.best_params_[\"C\"], penalty=gs.best_params_[\"penalty\"], solver='liblinear')\n",
    "gs_logreg.fit(Xt, y)\n",
    "np.abs(gs_logreg.coef_)\n",
    "lr_columns_order=[5,3,2,7,4,1,6]\n",
    "lr_columns=      [0,1,1,0,1,1,0]\n",
    "lr_columns_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare features sets\n",
    "\n",
    "Use the `best estimator` from question 4 on the 3 different feature sets:\n",
    "\n",
    "- `kbest_columns`\n",
    "- `rfecv_columns`\n",
    "- `lr_columns`\n",
    "- `all_columns`\n",
    "\n",
    "Questions:\n",
    "\n",
    "- Which scores the highest? (use cross_val_score)\n",
    "- Is the difference significant?\n",
    "- discuss in pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77330092663\n",
      "0.619535553572\n",
      "0.619535553572\n",
      "0.79574180603\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "gs_logreg = LogisticRegression(C=gs.best_params_[\"C\"], penalty=gs.best_params_[\"penalty\"], solver='liblinear')\n",
    "\n",
    "# Kbest\n",
    "gs_logreg.fit(Xt[kbest_columns], y)\n",
    "accuracies = cross_val_score(gs_logreg, Xt[kbest_columns], y, cv=5)\n",
    "print(np.mean(accuracies))\n",
    "\n",
    "# RFEcv\n",
    "gs_logreg.fit(Xt[rfecv_columns], y)\n",
    "accuracies = cross_val_score(gs_logreg, Xt[rfecv_columns], y, cv=5)\n",
    "print(np.mean(accuracies))\n",
    "\n",
    "# lr\n",
    "gs_logreg.fit(Xt[lr_columns], y)\n",
    "accuracies = cross_val_score(gs_logreg, Xt[lr_columns], y, cv=5)\n",
    "print(np.mean(accuracies))\n",
    "\n",
    "# all\n",
    "gs_logreg.fit(Xt, y)\n",
    "accuracies = cross_val_score(gs_logreg, Xt, y, cv=5)\n",
    "print(np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "Use a bar chart to display the logistic regression coefficients. Start from the most negative on the left. Can you come up with bar chart rankings for the other methods also? How about a heat map like we talked about in the lecture?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
