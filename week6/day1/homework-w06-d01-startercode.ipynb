{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework w06d01\n",
    "\n",
    "\n",
    "### Read in the Wisconsin Breast Cancer Dataset\n",
    "\n",
    "### Assign the columns\n",
    "\n",
    "The attributes below will be the columns of the dataset.\n",
    "  \n",
    "Attribute                     \n",
    "\n",
    "1. Sample code number [subject ID]\n",
    "1. Class\n",
    "1. Cell nucleus mean radius\n",
    "1. Cell nucleus SE radius\n",
    "1. Cell nucleus worst radius\n",
    "1. Texture mean\n",
    "1. Texture SE\n",
    "1. Texture worst\n",
    "1. Perimeter mean\n",
    "1. Perimeter SE\n",
    "1. Perimeter worst\n",
    "1. Area mean\n",
    "1. Area SE\n",
    "1. Area worst\n",
    "1. Smoothness mean\n",
    "1. Smoothness SE\n",
    "1. Smoothness worst\n",
    "1. Compactness mean\n",
    "1. Compactness SE\n",
    "1. Compactness worst\n",
    "1. Concavity mean\n",
    "1. Concavity SE\n",
    "1. Concavity worst\n",
    "1. Concave points mean\n",
    "1. Concave points SE\n",
    "1. Concave points worst\n",
    "1. Symmetry mean\n",
    "1. Symmetry SE\n",
    "1. Symmetry worst\n",
    "1. Fractal dimension mean\n",
    "1. Fractal dimension SE\n",
    "1. Fractal dimension worst\n",
    "\n",
    "The column names are taken from the dataset info file.\n",
    "For more information check out the information file: wdbc.names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, average_precision_score, f1_score, recall_score, precision_score\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\", header=None)\n",
    "\n",
    "column_names = ['id','malignant',\n",
    "                'nucleus_mean','nucleus_se','nucleus_worst',\n",
    "                'texture_mean','texture_se','texture_worst',\n",
    "                'perimeter_mean','perimeter_se','perimeter_worst',\n",
    "                'area_mean','area_se','area_worst',\n",
    "                'smoothness_mean','smoothness_se','smoothness_worst',\n",
    "                'compactness_mean','compactness_se','compactness_worst',\n",
    "                'concavity_mean','concavity_se','concavity_worst',\n",
    "                'concave_pts_mean','concave_pts_se','concave_pts_worst',\n",
    "                'symmetry_mean','symmetry_se','symmetry_worst',\n",
    "                'fractal_dim_mean','fractal_dim_se','fractal_dim_worst']\n",
    "\n",
    "df.columns = column_names\n",
    "\n",
    "# Define the feature matrix X\n",
    "X = df.iloc[:,2:]\n",
    "\n",
    "#Define the response y and recode it numerically\n",
    "y = df.malignant\n",
    "y = y.map(lambda x: 0 if x == \"B\" else 1)\n",
    "print y.head()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Use the standard scaler to transform the feature matrix X, put the output into a pandas data frame and assign the appropriate column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Build a classification tree of depth 3 on the training set and determine the model accuracy, the confusion matrix and the classification report  on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Use the following function to create a png-file of the decision tree. Import the created png-file into the jupyter notebook by using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import system\n",
    "from sklearn.tree import export_graphviz\n",
    "def build_tree_image(model, filename='tree.png'):\n",
    "    dotfile = open(\"tree.dot\", 'w')\n",
    "    export_graphviz(model, out_file = dotfile, feature_names = X.columns,filled=True,\n",
    "                    rounded=True,special_characters=True)\n",
    "    dotfile.close()\n",
    "    system(\"dot -Tpng tree.dot -o {0}\".format(filename))  # comment out this line if you don't have GraphViz yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "build_tree_image(model,'tree_bc.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Include your tree here\n",
    "<img src='your_tree_bc.png' width= 80%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Use \"feature_importances_\" to obtain a rank list of the features according to their importance. Compare your results with the best subsetselection results based on logistic regression (homework w05d04)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute the feature importances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Perform grid search with five-fold cross validation varying the maximal depth, the maximal number of leaf nodes and the minimum number of samples in each leaf. Obtain the ROC curve for the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Grid Search\n",
    "\n",
    "#After completion, show the final best results and scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
