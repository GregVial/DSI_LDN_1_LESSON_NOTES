{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Case Study: A/B Testing with pymc3\n",
    "\n",
    "Week 9 | Lab 4.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most common applications of Bayesian analysis in industry is in A/B tests. In every major website you use it is likely that you have been part of an A/B test at some point and possibly even at any given time. A/B tests are essentially incrementally different versions of a product that are being tested on randomly selected users and evaluated on a performance metric. They are a good and widespread way to assess whether a proposed change will be beneficial, detrimental, or have no effect. To clarify, in an A/B test you would randomly assign some visitors to the site to one version of a page (group A) and some to another version (group B). Whichever performs better on your metric (click through rate, purchase, etc) then becomes the default. Gradually you hope to iterate towards a totally optimised webpage where every button is in the best position and every text as clear as it can be. Of course, this assumes that every customer responds the same way - there is a subdomain of such approaches where you actually show different categories of users different sites on an ongoing basis, but we will not get in to this and consider only the simpler (and more typical) case of which is the best overall version of a page/app.\n",
    "\n",
    "We have already seen much of the code and logic for this, but here we apply it to the specific context and hopefully add greater clarity through practice. If you find, for example, that when you move to a role in industry that your company is doing its A/B testing in a frequentist framework, you might want to approach them to discuss whether performing a Bayesian A/B testing might give them greater access to insight and allow them to make clear conclusions with fewer test subjects (and hence less time). This case study could help give you a framework from which to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pymc3 as pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load fitness app A/B test conversions data\n",
    "\n",
    "The dataset below contains information on user \"conversions\" on a fitness app on different \"arms\" of an A/B test. A conversion is whether or not a user performed a desired action or not (typically a purchase, or a click to the next part of the app).\n",
    "\n",
    "Arms are the different versions of a product in a currently running A/B test. A/B tests may also be referred to as split tests. The name A/B test does not necessarily imply only two splits.\n",
    "\n",
    "\n",
    "#### Data description\n",
    "\n",
    "The data has 6 columns:\n",
    "\n",
    "- arm: the version of the app this user was randomly assigned to\n",
    "- gender: male/female\n",
    "- age: age bins, one of 20-30, 30-40, 40-50\n",
    "- day: the day (total of 21 days)\n",
    "- fitness: the user's self reported fitness level from -5 to 5\n",
    "- converted: 1 if the user purchased the product, 0 if not\n",
    "    \n",
    "Each row is a unique user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(725, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arm</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>day</th>\n",
       "      <th>fitness</th>\n",
       "      <th>converted</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>female</td>\n",
       "      <td>20-30</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>female</td>\n",
       "      <td>40-50</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>female</td>\n",
       "      <td>30-40</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>female</td>\n",
       "      <td>20-30</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>male</td>\n",
       "      <td>30-40</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  arm  gender    age  day  fitness  converted  male\n",
       "0   A  female  20-30    0     -2.0          0     0\n",
       "1   A  female  40-50    0      3.0          0     0\n",
       "2   A  female  30-40    0     -5.0          0     0\n",
       "3   A  female  20-30    0     -4.0          0     0\n",
       "4   A    male  30-40    0      1.0          1     1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./assets/datasets/split_test_data.csv')\n",
    "data['male'] = data.gender.map(lambda x: 1 if x == 'male' else 0)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Examine the split test arm \"schedule\"\n",
    "\n",
    "When a new arm is introduced into an A/B test, it is generally tested at a low percentage of users initially before assignment becomes balanced between the arms. This ensures that if something is terribly wrong with one of the arms it does not ruin the experience for many potential customers. Find the counts assigned to each split test arm by day. Plot a chart to examine this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">fitness</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arm</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fitness          \n",
       "arm       A     B   C\n",
       "day                  \n",
       "0      26.0   NaN NaN\n",
       "1      40.0   4.0 NaN\n",
       "2      30.0   3.0 NaN\n",
       "3      30.0   3.0 NaN\n",
       "4      18.0  18.0 NaN"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_schedule = pd.pivot_table(data, index=[\"day\"], columns=[\"arm\"], values=[\"fitness\"], aggfunc=len)\n",
    "split_schedule.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11b155450>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApkAAAHzCAYAAABrKAbzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119f26d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split_schedule.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check:** how many arms are there?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Look at mean conversion rate overall and by arm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arm</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.185393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.116667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.255814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0.175172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     converted\n",
       "arm           \n",
       "A     0.185393\n",
       "B     0.116667\n",
       "C     0.255814\n",
       "All   0.175172"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_conversion_rates = pd.pivot_table(data, index=[\"arm\"], values=[\"converted\"], aggfunc=\"mean\", margins=True)\n",
    "mean_conversion_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Look at overall conversion rate differences along age, gender, and fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20-30</th>\n",
       "      <td>0.253112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30-40</th>\n",
       "      <td>0.155738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40-50</th>\n",
       "      <td>0.116667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0.175172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       converted\n",
       "age             \n",
       "20-30   0.253112\n",
       "30-40   0.155738\n",
       "40-50   0.116667\n",
       "All     0.175172"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversion_rate_age = pd.pivot_table(data, index=[\"age\"], values=[\"converted\"], aggfunc=\"mean\", margins=True)\n",
    "conversion_rate_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>0.206897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.145889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0.175172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        converted\n",
       "gender           \n",
       "female   0.206897\n",
       "male     0.145889\n",
       "All      0.175172"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversion_rate_gender = pd.pivot_table(data, index=[\"gender\"], values=[\"converted\"], aggfunc=\"mean\", margins=True)\n",
    "conversion_rate_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fitness</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-5.0</th>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-4.0</th>\n",
       "      <td>0.026316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-3.0</th>\n",
       "      <td>0.073171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.0</th>\n",
       "      <td>0.148649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1.0</th>\n",
       "      <td>0.086957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.179487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.161290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.171053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.276923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.391892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.484848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0.175172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         converted\n",
       "fitness           \n",
       "-5.0      0.055556\n",
       "-4.0      0.026316\n",
       "-3.0      0.073171\n",
       "-2.0      0.148649\n",
       "-1.0      0.086957\n",
       "0.0       0.179487\n",
       "1.0       0.161290\n",
       "2.0       0.171053\n",
       "3.0       0.276923\n",
       "4.0       0.391892\n",
       "5.0       0.484848\n",
       "All       0.175172"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversion_rate_fitness = pd.pivot_table(data, index=[\"fitness\"], values=[\"converted\"], aggfunc=\"mean\", margins=True)\n",
    "conversion_rate_fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model conversion rates through day 5 with `pymc3`\n",
    "\n",
    "We will start by just modeling the conversion rate distributions for arms A and B through to day 5. By day 5, arm C has not been introduced yet and so there are still just 2 arms.\n",
    "\n",
    "### 2.1 Subset the data to the first 5 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172, 7)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_five_days = data[data[\"day\"]<5]\n",
    "first_five_days.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Set up a `pymc3` model and uniform priors for the probabilities of conversion for arms A and B\n",
    "\n",
    "Recall that `pymc3` uses the `with ...` syntax for defining models. The first step in setting up a new model is to define the model as the \"context\" like so:\n",
    "\n",
    ">```python\n",
    "day5_model=pm.Model()\n",
    "with day5_model:\n",
    "    #\n",
    "```\n",
    "\n",
    "We are going to model the _probability distributions for conversion rates for arms A and B._ As always with Bayesian statistics, we need to define prior distributions for our belief about these probabilities/rates of conversion per arm. Let's say we have no belief whatsoever about rates, and so we will set an uninformative, flat prior over probabilities from 0 to 1 for both arms. This is equivalent to saying that we believe all conversion rates to be equally likely for both arms. This prior will then not have an influence on the posterior outcome (but we still define it).\n",
    "\n",
    "The syntax for setting up this flat prior is:\n",
    "\n",
    ">```python\n",
    "arm_A_prior = pm.Uniform('A_prior', lower=0, upper=1)\n",
    "```\n",
    "\n",
    "Set up the priors for both arms inside the `with ...` model block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applied interval-transform to A_prior and added transformed A_prior_interval_ to model.\n",
      "Applied interval-transform to B_prior and added transformed B_prior_interval_ to model.\n"
     ]
    }
   ],
   "source": [
    "day5_model = pm.Model()\n",
    "with day5_model:\n",
    "    arm_A_prior = pm.Uniform('A_prior', lower=0, upper=1)\n",
    "    arm_B_prior = pm.Uniform('B_prior', lower=0, upper=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Set up `pm.Bernoulli` distributions to model conversions for arms A and B\n",
    "\n",
    "Now that you've initialised your model, your `with` statements will be\n",
    "\n",
    ">```python\n",
    "with day5_model:\n",
    "    #\n",
    "```\n",
    "\n",
    "Be careful not to re-define the model with `pm.Model()` or it will wipe the uniform priors you set before! We are now going to set up the \"likelihood\" portion of the model. This is going to model the $P(data\\;|\\;\\theta)$ part of Bayes theorem. Our conversions are represented by a vector of 1s and 0s denoting whether or not the user converted or not. This is hence a \"Bernoulli\" process and pymc3 has an approprite function to handle it:\n",
    "\n",
    ">```python\n",
    "A_conversions = pm.Bernoulli('A_conversions', p=arm_A_prior, observed=arm_A_conversions)\n",
    "```\n",
    "\n",
    "`p=` (probability of success) is set to the prior for the arm that you defined in the last section. `observed=` should be set to the `converted` values for that arm specifically in the data. By giving it an `observed` parameter, we are telling pymc3 that we want this to evaluate the likelihood of our data (the conversions) against models represented by the `p=` probability argument. We assign `p=` to be our prior belief about conversion rates in the first instance for that arm because we then want to update this belief (convert to posterior) based on the conversion data we have observed for that arm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      False\n",
       "1      False\n",
       "2      False\n",
       "3      False\n",
       "4       True\n",
       "5      False\n",
       "6      False\n",
       "7      False\n",
       "8      False\n",
       "9      False\n",
       "10      True\n",
       "11     False\n",
       "12     False\n",
       "13     False\n",
       "14     False\n",
       "15     False\n",
       "16     False\n",
       "17     False\n",
       "18      True\n",
       "19     False\n",
       "20     False\n",
       "21     False\n",
       "22      True\n",
       "23     False\n",
       "24     False\n",
       "25     False\n",
       "26     False\n",
       "27     False\n",
       "28     False\n",
       "29     False\n",
       "       ...  \n",
       "142    False\n",
       "143    False\n",
       "144    False\n",
       "145    False\n",
       "146    False\n",
       "147    False\n",
       "148    False\n",
       "149    False\n",
       "150    False\n",
       "151    False\n",
       "152    False\n",
       "153    False\n",
       "154    False\n",
       "155    False\n",
       "156    False\n",
       "157    False\n",
       "158    False\n",
       "159    False\n",
       "160    False\n",
       "161    False\n",
       "162    False\n",
       "163    False\n",
       "164    False\n",
       "165    False\n",
       "166    False\n",
       "167    False\n",
       "168    False\n",
       "169    False\n",
       "170    False\n",
       "171    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arm_A_conversions = (first_five_days[\"arm\"] == \"A\") & (first_five_days[\"converted\"] == 1)\n",
    "arm_A_conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with day5_model:\n",
    "    A_conversions = pm.Bernoulli('A_conversions', p=arm_A_prior, observed=arm_A_conversions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Fit the model using MCMC\n",
    "\n",
    "Now that we've set up the prior distributions and likelihoods, we can actually fit the model. Below is code that will run MCMC on the model we have parameterised:\n",
    "\n",
    ">```python\n",
    "with day5_model:\n",
    "    start = pm.find_MAP()\n",
    "    trace = pm.sample(10000, start=start)\n",
    "```\n",
    "\n",
    "Again you use the context `with day5_model:` to run code for your model.\n",
    "\n",
    "`start = pm.find_MAP()` will try to find a good starting point for the MCMC sampling process. This means that your model will converge on the \"likely\" area much faster (though it makes the fitting slower initially). We skipped over this when we looked at pymc3 previously and stated you would have to input some starting point randomly. This function is an attempt to find a sensible starting point that is likely to be close to the true value (it stands for maximum aposteriori estimate).\n",
    "\n",
    "`trace = pm.sample(10000, start=start)` uses the sampling method in pymc3 to perform 10,000 MCMC sampling iterations. This will automatically assign the NUTS sampler for you, which is more advanced but actually slower than the Metropolis-Hastings sampling we covered in class. The dataset is small so the speed shouldn't be so noticeable. You can optionally set the sampler to Metropolis with the keyword in the `pm.sample(step=pm.Metropolis())` When this completes, the `trace` variable now contains the posterior samples for the distributions we specified while constructing the model.\n",
    "\n",
    ">```python\n",
    "# We defined our arm A prior distribution to be uniform and named it 'arm_A_prior'. \n",
    "# The pm.sample() procedure converted this into our posterior belief for the rate\n",
    "# of conversions in arm A. You can access these posterior samples using the name\n",
    "# you gave the variable when you created it:\n",
    "#\n",
    "trace['arm_A_prior']\n",
    "#\n",
    "# this will be a vector of values that are different potential rates of conversion\n",
    "# for arm A. A histogram of these rates defines, roughly, the posterior probability\n",
    "# distribution for the arm A rates after we consider the data we have collected.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Use `pm.traceplot` to look at your posterior distributions\n",
    "\n",
    "The `pm.traceplot()` function accepts the trace variable from your model sampling and will plot out the posterior distributions for all of the distributions you defined. Recall it is best practice to get rid of a portion of the first samples; after some iterations the MCMC sampling procedure will make its way to the most likely region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check:** what are the left and right hand side plots return by the traceplot function telling you?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Write a function to plot your data distributions using `sns.distplot`\n",
    "\n",
    "Your function should:\n",
    "\n",
    "1. Accept the trace values to plot as an argument.\n",
    "- Accept a list of names to label each trace.\n",
    "- Plot the traces on the same axis using `sns.distplot(...)` with `kde=True` in different colors for each distribution.\n",
    "- Have a legend that labels the distributions.\n",
    "\n",
    "Say you had defined a prior\n",
    "\n",
    ">```python\n",
    "A_p = pm.Uniform('A_prob', lower=0, upper=1)\n",
    "```\n",
    "\n",
    "and then fit the model using `pm.sample(...)` like so\n",
    "\n",
    ">```python\n",
    "with model:\n",
    "    start = pm.find_MAP()\n",
    "    trace = pm.sample(10000, start=start)\n",
    "```\n",
    "\n",
    "The `trace` variable now contains the samples of your posterior distribution for `A_prob` (and every other prior distribution that was converted to a posterior during the sampling process). You can access the values like so:\n",
    "\n",
    ">```python\n",
    "A_prob_trace_values = trace['A_prob']\n",
    "```\n",
    "\n",
    "You'll typically want to discard a portion of the starting MCMC samples as the process may still be searching for the \"likely\" area during that start-up period:\n",
    "\n",
    ">```python\n",
    "A_prob_trace_values = trace[1000:]['A_prob']\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "You can pass an existing axis as a keyword argument into the function: `sns.distplot(..., ax=ax)` and it will plot the distribution on the existing axis. The distplot function also accepts a label argument: `sns.distplot(..., label=label)`. To show the legend, you can use `ax.legend(loc='upper right')` or whatever location you think looks best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Re-build the same model, but add a `pm.Deterministic` variable that calculates the difference between A and B conversion rates\n",
    "\n",
    "For example, if I have two priors\n",
    "\n",
    ">```python\n",
    "A_p = pm.Uniform('A_prob', lower=0, upper=1)\n",
    "B_p = pm.Uniform('B_prob', lower=0, upper=1)\n",
    "```\n",
    "\n",
    "I can set up a \"deterministic\" variable that is some specific calculation I want to do on each iteration of the MCMC sampling process\n",
    "\n",
    ">```python\n",
    "AvB = pm.Deterministic('AvB', A_p - B_p)\n",
    "```\n",
    "\n",
    "This will be a distribution with the differences between `A_p` and `A_b` on each sampling iteration; a posterior of the differences. Recreate the model we built and ran above, but add the determinisic variable in the model definition before you do the sampling procedure. Recall that this allows us to describe the difference between the two groups. So in this case, you should reinitialise with `pm.Model()` and rebuild the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Plot the posterior of the differences between arms using `pm.plot_posterior`\n",
    "\n",
    "You can specify in `varnames` which posterior distribution you want to plot from your trace using the function, like so:\n",
    "\n",
    ">```python\n",
    "pm.plot_posterior(trace[5000:], varnames=['AvB'], color='#87ceeb', ref_val=0.)\n",
    "```\n",
    "\n",
    "In the above example, `ref_val=0` will plot a bar at 0 on the x-axis, which is useful for visualizing the proportion of the distribution of differences does not contain 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 Based on the posterior distribution of differences, what can you say about the split test arms? What is the probability one is better than another?\n",
    "\n",
    "Take a look back at previous lessons/labs if you are unsure of the interpretation. Also try Chapter 2 of _Bayesian Methods for Hackers_ [here](http://nbviewer.jupyter.org/github/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/tree/master/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Perform the same analysis through day 8\n",
    "\n",
    "We are going to do the same model-buidling process we went through above, but now on the data through day 8. **Subset to just the first 8 days:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Build and fit the day 8 model\n",
    "\n",
    "This will be the same specification as your model for day 5. Keep the deterministic distribution that models the differences between arm A's rate and arm B's rate that we added in the second half of question 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Plot the traces with `pm.traceplot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Plot the posterior distributions for arms A and B with your custom function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Plot the posterior distribution of differences between A and B with `pm.plot_posterior`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Again based on the posterior distribution of differences, what can you say about the split test arms now?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Bonus] dealing with more than two arms\n",
    "\n",
    "This introduces a new concept of hierarchical modelling for multiple arm tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Build and fit the model\n",
    "\n",
    "You will now need to reinitialise the model again and add in capability for handling the third arm. You should also now calculate 3 \"deterministic\" variables that look at differences between the three arms:\n",
    "\n",
    "- `A` vs. `B`\n",
    "- `A` vs. `C`\n",
    "- `B` vs. `C`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Plot the distributions for the arms using your custom function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Plot the three difference measure posterior distributions using `pm.plot_posterior`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Perform a hierarchical split test analysis for data through to day 11\n",
    "\n",
    "The problem with multiple comparisons is that if we take a standard AvB approach for every case we could overestimate the significance of differences. Thus far we have been constructing our models as **unpooled** models. This means that we are modeling the effect of arms A, B, and C on conversion rate independently. On the opposite end of this spectrum we would have a **pooled** model, where we would instead model A, B, and C with a single parameter. To do this, we would have to code the arms as numbers and then fit a single coefficient on them.\n",
    "\n",
    "In this case we can build a **partial pooling** model. In partial pooling, each arm gets its own effect like in the unpooled model, but they _share a prior for how they are parameterised_. This means that if we have an arm with very few observations like arm C, our estimation for the conversion rate of arm C will be a combination of the overall conversion rate across arms and the specific conversion rate for just arm C's data. The less data any arm has, the more its estimation will shrink towards the overall conversion rate. See [here](http://twiecki.github.io/blog/2014/03/17/bayesian-glms-3/) for another detailed overview of hierarchical modeling and partial pooling with pymc3. [This](http://sl8r000.github.io/ab_testing_statistics/use_a_hierarchical_model/) also has a good discussion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Build and fit the hierarchical model\n",
    "\n",
    "Now that we are building a hierarchical model, a few things are going to change. \n",
    "\n",
    "**1. Set up distributions for \"group level\" alpha and beta.**\n",
    "\n",
    "We need to have a prior for the \"overall\" or \"across-arm\" alpha and beta values that will define their Beta distributions. The prior/posterior for each arm is going to be modeled with a Beta distribution, which is a handy distribution for modelling probability of occurances or rates (we saw this before - when coupled to a binomial case then the posterior of a beta prior is also a beta). The beta distribution, as you may recall, is parameterised by an alpha and beta parameter:\n",
    "\n",
    "    alpha: successes + 1\n",
    "    beta: failures + 1\n",
    "    \n",
    "Where successes will be conversions and failures will be non-conversions. Arm A, for example, can be set up in pymc3 like:\n",
    "\n",
    ">```python\n",
    "A_prior = pm.Beta('A_prior', alpha=?, beta=?)\n",
    "```\n",
    "\n",
    "As you can see, question marks have beeb placed in the alpha and beta keyword assignments. If we set alpha=1 and beta=1, this would be a uniform prior for arm A, like we were doing before. We could set alpha and beta as higher values and have a stronger prior belief about conversions. But what we need for our hierarchical model is that the three priors for arms A, B, and C _share_ a prior belief about what alpha and beta should be. So we want something like\n",
    "\n",
    ">```python\n",
    "A_prior = pm.Beta('A_prior', alpha=group_alpha, beta=group_beta)\n",
    "B_prior = pm.Beta('B_prior', alpha=group_alpha, beta=group_beta)\n",
    "```\n",
    "\n",
    "Where `group_alpha` and `group_beta` are themselves prior distributions for likely values of alpha and beta. By having all the A, B, and C arm priors share the same alpha and beta prior beliefs, we tie them together and achieve partial pooling. For example, imagine that we have very few observations of successes and failures (like with arm C). Because there are so few datapoints, the prior will not change much from the distribution defined by `group_alpha` and `group_beta`.\n",
    "\n",
    "On the other hand, if we have a lot of observations like with arm A, the quantity of data will have a strong effect on the prior-to-posterior conversion and so our posterior will be more defined by the data tahn by `group_alpha` and `group_beta`. This means that with little data, the rate distribution for an arm shrinks towards the overall group conversion rate. To set up a group alpha and beta prior, we can use the `pm.Gamma()` distribution. The gamma distribution is strictly positive and in pymc we can define it with a mean and standard deviation. For the group level alpha, for example:\n",
    "\n",
    ">```python\n",
    "group_alpha = pm.Gamma('group_alpha', mu=10, sd=100)\n",
    "```\n",
    "\n",
    "The high standard deviation means that larger values are close in likelihood to smaller values, which is good since we want this to be fairly uninformative.\n",
    "\n",
    "\n",
    "#### Construct the hierarchical model\n",
    "\n",
    "Given all the information above, try to build the hierarchical model with group level alpha/beta priors and arm prior distributions defined by `pm.Beta` distributions that accept the group alpha and beta values as parameters. The rest of the model structure should essentially be the same as what you've been doing so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Plot the arm conversion rate distributions from your hierarchical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 6.3 Plot the distribution for arm C from the non-hierarchical (unpooled) model vs the hierarchical (pooled) model\n",
    "\n",
    "NOTE: if the \"trace\" variable is named the same thing for the hierarchical model and unpooled model, then it probably overwrote the original trace. \n",
    "\n",
    "Make sure that the trace variable for your original and hierarchical models are named different things before doing this section (you may have to re-run the model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 6.4 Plot the posterior difference variables with `pm.plot_posterior`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Make a hierarchical split test model for the whole dataset\n",
    "\n",
    "Now do the same thing you just did above for the hierarchical model, but use the entire 21 days of data in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 7.1 Build the hierarchical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 7.2 Plot the conversion rate distributions for arms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 7.3 Plot the posterior distributions for differences between arms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
