{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "cc166dbc-d723-4076-8dd8-a290d911dc9b"
   },
   "source": [
    "# Web Scraping for Indeed.com and Predicting Salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "59b0deac-55d6-4908-8dee-ce68611486f0"
   },
   "source": [
    "In this project, we will practice two major skills: collecting data by scraping a website and then building a binary predictor with Logistic Regression.\n",
    "\n",
    "We are going to collect salary information on data science jobs in a variety of markets. Then using the location, title and summary of the job we will attempt to predict the salary of the job. For job posting sites, this would be extraordinarily useful. While most listings DO NOT come with salary information (as you will see in this exercise), being to able extrapolate or predict the expected salaries from other listings can help guide negotiations.\n",
    "\n",
    "Normally, we could use regression for this task; however, we will convert this problem into classification and use Logistic Regression.\n",
    "\n",
    "- Question: Why would we want this to be a classification problem?\n",
    "- Answer: While more precision may be better, there is a fair amount of natural variance in job salaries - predicting a range be may be useful.\n",
    "\n",
    "Therefore, the first part of the assignment will be focused on scraping Indeed.com. In the second, we'll focus on using listings with salary information to build a model and predict additional salaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "1321e3c4-2105-428e-9b1b-6d958453ef1d"
   },
   "source": [
    "### Scraping job listings from Indeed.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9d959074-bf26-4000-b0da-11273e253776"
   },
   "source": [
    "We will be scraping job listings from Indeed.com using BeautifulSoup. Luckily, Indeed.com is a simple text page where we can easily find relevant entries.\n",
    "\n",
    "First, look at the source of an Indeed.com page: (http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\")\n",
    "\n",
    "Notice, each job listing is underneath a `div` tag with a class name of `result`. We can use BeautifulSoup to extract those. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "d9f7b5d1-b227-4bda-a87b-1606b62fb60b"
   },
   "source": [
    "#### Setup a request (using `requests`) to the URL below. Use BeautifulSoup to parse the page and extract all results (HINT: Look for div tags with class name result)\n",
    "\n",
    "The URL here has many query parameters\n",
    "\n",
    "- `q` for the job search\n",
    "- This is followed by \"+20,000\" to return results with salaries (or expected salaries >$20,000)\n",
    "- `l` for a location \n",
    "- `start` for what result number to start on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "911505d6-159f-4146-967d-a8482fe27e3d"
   },
   "outputs": [],
   "source": [
    "URL = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "78446809-fa02-48df-b60f-cbeda175a498"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "c8846f3e-42a5-4714-9784-fb5d6a28524b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arahuja/anaconda/envs/py34/lib/python3.4/site-packages/bs4/__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "r = requests.get(URL)\n",
    "soup = BeautifulSoup(r.content)\n",
    "# Append to the full set of results\n",
    "results = soup.findAll('div', { \"class\" : \"result\" })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "963bb376-7746-43ce-98ec-ea4162f7ead6"
   },
   "source": [
    "Let's look at one result more closely. A single `result` looks like\n",
    "\n",
    "```\n",
    "<div class=\" row result\" data-jk=\"2480d203f7e97210\" data-tn-component=\"organicJob\" id=\"p_2480d203f7e97210\" itemscope=\"\" itemtype=\"http://schema.org/JobPosting\">\n",
    "<h2 class=\"jobtitle\" id=\"jl_2480d203f7e97210\">\n",
    "<a class=\"turnstileLink\" data-tn-element=\"jobTitle\" onmousedown=\"return rclk(this,jobmap[0],1);\" rel=\"nofollow\" target=\"_blank\" title=\"AVP/Quantitative Analyst\">AVP/Quantitative Analyst</a>\n",
    "</h2>\n",
    "<span class=\"company\" itemprop=\"hiringOrganization\" itemtype=\"http://schema.org/Organization\">\n",
    "<span itemprop=\"name\">\n",
    "<a href=\"/cmp/Alliancebernstein?from=SERP&amp;campaignid=serp-linkcompanyname&amp;fromjk=2480d203f7e97210&amp;jcid=b374f2a780e04789\" target=\"_blank\">\n",
    "    AllianceBernstein</a></span>\n",
    "</span>\n",
    "<tr>\n",
    "<td class=\"snip\">\n",
    "<nobr>$117,500 - $127,500 a year</nobr>\n",
    "<div>\n",
    "<span class=\"summary\" itemprop=\"description\">\n",
    "C onduct quantitative and statistical research as well as portfolio management for various investment portfolios. Collaborate with Quantitative Analysts and</span>\n",
    "</div>\n",
    "</div>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "</div>\n",
    "```\n",
    "\n",
    "While this has some of the more verbose elements removed, we can see that there is some structure to the above:\n",
    "- The salary is available in a `nobr` element inside of a `td` element with `class='snip`.\n",
    "- The title of a job is in a link with class set to `jobtitle` and a `data-tn-element=\"jobTitle`.  \n",
    "- The location is set in a `span` with `class='location'`. \n",
    "- The company is set in a `span` with `class='company'`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "27b6ffb9-b42f-4298-b07a-10e3bab030cd"
   },
   "source": [
    "### Write 4 functions to extract each item: location, company, job, and salary.\n",
    "\n",
    "example: \n",
    "```python\n",
    "def extract_location_from_result(result):\n",
    "    return result.find ...\n",
    "```\n",
    "\n",
    "\n",
    "- Make sure these functions are robust and can handle cases where the data/field may not be available.\n",
    "- Test the functions on the results above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "f4b0755f-42e1-438f-89fc-131a60b781cd"
   },
   "outputs": [],
   "source": [
    "def extract_text(el):\n",
    "    if el:\n",
    "        return el.text.strip()\n",
    "    else:\n",
    "        return ''\n",
    "        \n",
    "\n",
    "def get_company_from_result(result):\n",
    "    return extract_text(result.find('span', {'class' : 'company'}))\n",
    "\n",
    "def get_location_from_result(result):\n",
    "    return  extract_text(result.find('span', {'class' : 'location'}))\n",
    "\n",
    "def get_summary_from_result(result):\n",
    "    return  extract_text(result.find('span', {'class' : 'summary'}))\n",
    "\n",
    "def get_title_from_result(result):\n",
    "    return result.find('a', {'data-tn-element' : 'jobTitle'}).text.strip()\n",
    "\n",
    "def get_salary_from_result(result):\n",
    "    salary_table = result.find('td', {'class' : 'snip'})\n",
    "    if salary_table:\n",
    "        snip = salary_table.find('nobr')\n",
    "        if snip:\n",
    "            return snip.text.strip()\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "dc1d32a3-b13c-4919-8723-ce50dbc7660f"
   },
   "source": [
    "Now, to scale up our scraping, we need to accumulate more results. We can do this by examining the URL above.\n",
    "\n",
    "- \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\"\n",
    "\n",
    "There are two query parameters here we can alter to collect more results: the `l=New+York` and the `start=10`. The first controls the location of the results (so we can try different city). The second controls where in the results to start and gives 10 results (so we can keep incrementing this by 10 to move further within the list)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "27584c3f-f552-40a2-842a-0681b1fd6265"
   },
   "source": [
    "#### Complete the following code to collect results from multiple cities and start points. \n",
    "- Enter your city below to add it to the search\n",
    "- Remember to convert your salary to U.S. Dollars to match the other cities if the currency is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "20a34e35-a4db-44eb-8490-9903f8bcf406"
   },
   "outputs": [],
   "source": [
    "YOUR_CITY = 'Atlanta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "b02e2931-4d5a-4e1e-9504-c6ccaaf84bed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arahuja/anaconda/envs/py34/lib/python3.4/site-packages/bs4/__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "url_template = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l={}&start={}\"\n",
    "max_results_per_city = 100\n",
    "\n",
    "results = []\n",
    "\n",
    "for city in set(['New+York', 'Chicago', 'San+Francisco', 'Austin', 'Seattle', \n",
    "    'Los+Angeles', 'Philadelphia', 'Atlanta', 'Dallas', 'Pittsburgh', \n",
    "    'Portland', 'Phoenix', 'Denver', 'Houston', 'Miami', YOUR_CITY]):\n",
    "    for start in range(0, max_results_per_city, 10):\n",
    "        r = requests.get(url_template.format(city, start))\n",
    "        # Grab the results from the request (as above)\n",
    "        soup = BeautifulSoup(r.content)\n",
    "        # Append to the full set of results\n",
    "        results += soup.findAll('div', { \"class\" : \"result\" })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "10eb5902-4727-4947-a167-2531aa12a427"
   },
   "source": [
    "#### Use the functions you wrote above to parse out the 4 fields - location, title, company and salary. Create a dataframe from the results with those 4 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "d601ff2f-fbdf-4c4f-8bbe-10c4a3132cc8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seattle</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>None</td>\n",
       "      <td>Exceptional data science related experience wi...</td>\n",
       "      <td>Senior Manager - Senior Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Seattle</td>\n",
       "      <td>Lancer Insurance Company</td>\n",
       "      <td>None</td>\n",
       "      <td>Lancer Insurance Company is looking for a tale...</td>\n",
       "      <td>Data Scientist &amp; Analytics Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Seattle</td>\n",
       "      <td>Eli Lilly</td>\n",
       "      <td>None</td>\n",
       "      <td>Deliver next generation data integration and a...</td>\n",
       "      <td>IT Research Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Seattle</td>\n",
       "      <td>Amazon Web Services, Inc.</td>\n",
       "      <td>None</td>\n",
       "      <td>Interested in creating new state-of-the-art so...</td>\n",
       "      <td>Data Scientist - NYC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Seattle</td>\n",
       "      <td>ShopKeep</td>\n",
       "      <td>None</td>\n",
       "      <td>We have a mature data infrastructure, and we’d...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      city                    company salary  \\\n",
       "0  Seattle                      Aetna   None   \n",
       "1  Seattle   Lancer Insurance Company   None   \n",
       "2  Seattle                  Eli Lilly   None   \n",
       "3  Seattle  Amazon Web Services, Inc.   None   \n",
       "4  Seattle                   ShopKeep   None   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Exceptional data science related experience wi...   \n",
       "1  Lancer Insurance Company is looking for a tale...   \n",
       "2  Deliver next generation data integration and a...   \n",
       "3  Interested in creating new state-of-the-art so...   \n",
       "4  We have a mature data infrastructure, and we’d...   \n",
       "\n",
       "                                    title  \n",
       "0  Senior Manager - Senior Data Scientist  \n",
       "1    Data Scientist & Analytics Developer  \n",
       "2                   IT Research Scientist  \n",
       "3                    Data Scientist - NYC  \n",
       "4                          Data Scientist  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "for result in results:\n",
    "    if result:\n",
    "        row = {}\n",
    "        row['title'] = get_title_from_result(result)\n",
    "        row['company'] = get_company_from_result(result)\n",
    "        row['summary'] = get_summary_from_result(result)\n",
    "        row['salary'] = get_salary_from_result(result)\n",
    "        row['city'] = city\n",
    "        rows.append(row)\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.DataFrame.from_records(rows)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "faac26dc-392a-4f90-a397-144a070702cb"
   },
   "source": [
    "Lastly, we need to clean up salary data. \n",
    "\n",
    "1. Only a small number of the scraped results have salary information - only these will be used for modeling.\n",
    "1. Some of the salaries are not yearly but hourly or weekly, these will not be useful to us for now\n",
    "1. Some of the entries may be duplicated\n",
    "1. The salaries are given as text and usually with ranges.\n",
    "\n",
    "#### Find the entries with annual salary entries, by filtering the entries without salaries or salaries that are not yearly (filter those that refer to hour or week). Also, remove duplicate entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "58ff72c5-eef2-4a86-93ac-22f84ed9b752"
   },
   "outputs": [],
   "source": [
    "# Filter to only the rows that have salary entries\n",
    "data = data[data.salary.notnull()]\n",
    "\n",
    "# Remove duplicates\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "# Filter out salary entries referring to week, hour or month\n",
    "data = data[~(data.salary.astype('str').str.contains('hr'))]\n",
    "data = data[~(data.salary.astype('str').str.contains('hour'))]\n",
    "data = data[~(data.salary.astype('str').str.contains('week'))]\n",
    "data = data[~(data.salary.astype('str').str.contains('wk'))]\n",
    "data = data[~(data.salary.astype('str').str.contains('month'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "e1f58de9-78a7-49c1-b1ff-145a8f983790"
   },
   "source": [
    "#### Write a function that takes a salary string and converts it to a number, averaging a salary range if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "f2eaea83-8f84-48d3-af17-037538d06601"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "def extract_salary_average(salary_string):\n",
    "    regex = r'\\$([0-9]+,[0-9]+)'\n",
    "    matches = re.findall(regex, salary_string)\n",
    "    return np.mean([float(salary.replace(',', '')) for salary in matches ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "2d46d846-8aeb-49c3-86ac-768c4fc81552"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arahuja/anaconda/envs/py34/lib/python3.4/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "data['parsed_salary'] = data['salary'].map(extract_salary_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "5d66eb8a-a032-43f7-8e87-8f37612c2ce5"
   },
   "source": [
    "#### Save the scraped results as a CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "6e8a5a1c-1580-4845-a9b6-482bc00c73cd"
   },
   "source": [
    "## Predicting salaries using Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "eb63fd75-317d-429f-acc9-c4fd53357668"
   },
   "source": [
    "#### Load in the the data of scraped salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "634ab7c1-c76f-4b04-a36e-5ff3cb1f9eb2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>parsed_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Denver</td>\n",
       "      <td>Department Of The Interior</td>\n",
       "      <td>$76,341 - $99,243 a year</td>\n",
       "      <td>Would you like to join the more than 10,000 sc...</td>\n",
       "      <td>Statistician, GS-1350-12 (DEU-PERM-DS)</td>\n",
       "      <td>87792.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Denver</td>\n",
       "      <td>Department Of The Interior</td>\n",
       "      <td>$71,012 - $99,243 a year</td>\n",
       "      <td>Investigate potential uses of geospatial data ...</td>\n",
       "      <td>Interdisciplinary Cartographer/Geographer - GS...</td>\n",
       "      <td>85127.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Denver</td>\n",
       "      <td>Mental Health Center of Denver</td>\n",
       "      <td>$70,000 - $80,000 a year</td>\n",
       "      <td>Advise the Data Developer with regard to creat...</td>\n",
       "      <td>Financial Data Scientist</td>\n",
       "      <td>75000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Denver</td>\n",
       "      <td>Denver Public Schools</td>\n",
       "      <td>$62,712 - $75,255 a year</td>\n",
       "      <td>Portal managers on student outcome data report...</td>\n",
       "      <td>SENIOR RESEARCH ANALYST</td>\n",
       "      <td>68983.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Denver</td>\n",
       "      <td>University of Colorado</td>\n",
       "      <td>$25,000 - $29,000 a year</td>\n",
       "      <td>Experience entering and manipulating data in a...</td>\n",
       "      <td>Animal Care I</td>\n",
       "      <td>27000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     city                         company                    salary  \\\n",
       "0  Denver      Department Of The Interior  $76,341 - $99,243 a year   \n",
       "1  Denver      Department Of The Interior  $71,012 - $99,243 a year   \n",
       "2  Denver  Mental Health Center of Denver  $70,000 - $80,000 a year   \n",
       "3  Denver           Denver Public Schools  $62,712 - $75,255 a year   \n",
       "4  Denver          University of Colorado  $25,000 - $29,000 a year   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Would you like to join the more than 10,000 sc...   \n",
       "1  Investigate potential uses of geospatial data ...   \n",
       "2  Advise the Data Developer with regard to creat...   \n",
       "3  Portal managers on student outcome data report...   \n",
       "4  Experience entering and manipulating data in a...   \n",
       "\n",
       "                                               title  parsed_salary  \n",
       "0             Statistician, GS-1350-12 (DEU-PERM-DS)        87792.0  \n",
       "1  Interdisciplinary Cartographer/Geographer - GS...        85127.5  \n",
       "2                           Financial Data Scientist        75000.0  \n",
       "3                            SENIOR RESEARCH ANALYST        68983.5  \n",
       "4                                      Animal Care I        27000.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "salary_data = pd.read_csv('../assets/indeed-scraped-job-postings.csv')\n",
    "salary_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "c3ed6de7-8fe0-4cf4-abbd-abb2a188e05b"
   },
   "source": [
    "#### We want to predict a binary variable - whether the salary was low or high. Compute the median salary and create a new binary variable that is true when the salary is high (above the median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "073e3f3e-21bc-4ab7-ae2e-272be0a409cc"
   },
   "outputs": [],
   "source": [
    "median_salary = salary_data.parsed_salary.median()\n",
    "salary_data['HighSalary'] = (salary_data['parsed_salary'] > median_salary).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "3c7ec3d2-87a0-4290-9d83-a6f4a9ae7e9c"
   },
   "source": [
    "#### Thought experiment: What is the baseline accuracy for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "987666b2-d8e6-4715-b499-c9d314fb70ce"
   },
   "outputs": [],
   "source": [
    "# It is 50% if we guess randomly, half the salaries will be below the median and half will be above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "ea7e00cb-9956-44ec-b585-7b95f4d6284c"
   },
   "source": [
    "#### Create a Logistic Regression model to predict High/Low salary using statsmodel. Start by ONLY using the location as a feature. Display the coefficients and write a short summary of what they mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "ce9161b3-eff3-475c-a087-a2be38d7f626"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.593851\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arahuja/anaconda/envs/py34/lib/python3.4/site-packages/statsmodels/base/model.py:466: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>HighSalary</td>    <th>  No. Observations:  </th>  <td>   413</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   395</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>    17</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Mon, 11 Jul 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.1422</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>01:11:18</td>     <th>  Log-Likelihood:    </th> <td> -245.26</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>False</td>      <th>  LL-Null:           </th> <td> -285.92</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>2.234e-10</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>               <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>             <td>   -1.3218</td> <td>    0.563</td> <td>   -2.349</td> <td> 0.019</td> <td>   -2.425    -0.219</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city[T.Austin]</th>        <td>    1.0341</td> <td>    0.949</td> <td>    1.090</td> <td> 0.276</td> <td>   -0.825     2.893</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city[T.Boston]</th>        <td>    2.0794</td> <td>    0.644</td> <td>    3.230</td> <td> 0.001</td> <td>    0.817     3.341</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city[T.Chicago]</th>       <td>    1.4330</td> <td>    0.654</td> <td>    2.190</td> <td> 0.029</td> <td>    0.151     2.715</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city[T.Dallas]</th>        <td>    0.6286</td> <td>    0.832</td> <td>    0.756</td> <td> 0.450</td> <td>   -1.001     2.259</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city[T.Denver]</th>        <td>   -0.2187</td> <td>    0.849</td> <td>   -0.257</td> <td> 0.797</td> <td>   -1.883     1.446</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city[T.Houston]</th>       <td>  -22.8306</td> <td> 5.85e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-1.15e+05  1.15e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city[T.Los+Angeles]</th>   <td>    1.3218</td> <td>    0.695</td> <td>    1.901</td> <td> 0.057</td> <td>   -0.041     2.684</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city[T.Miami]</th>         <td>   -0.2877</td> <td>    1.232</td> <td>   -0.234</td> <td> 0.815</td> <td>   -2.701     2.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city[T.New+York]</th>      <td>    0.9886</td> <td>    0.597</td> <td>    1.656</td> <td> 0.098</td> <td>   -0.182     2.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city[T.Palo+Alto]</th>     <td>    2.1868</td> <td>    0.703</td> <td>    3.110</td> <td> 0.002</td> <td>    0.809     3.565</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city[T.Philadelphia]</th>  <td>    1.8814</td> <td>    0.842</td> <td>    2.234</td> <td> 0.026</td> <td>    0.230     3.532</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city[T.Phoenix]</th>       <td>  -24.0875</td> <td> 1.34e+05</td> <td>   -0.000</td> <td> 1.000</td> <td>-2.63e+05  2.63e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city[T.Pittsburgh]</th>    <td>  -22.8306</td> <td> 5.85e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-1.15e+05  1.15e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city[T.Portland]</th>      <td>  -15.4028</td> <td> 4282.475</td> <td>   -0.004</td> <td> 0.997</td> <td>-8408.899  8378.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city[T.San+Diego]</th>     <td>    0.9163</td> <td>    0.856</td> <td>    1.070</td> <td> 0.285</td> <td>   -0.762     2.595</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city[T.San+Francisco]</th> <td>    2.4478</td> <td>    0.653</td> <td>    3.746</td> <td> 0.000</td> <td>    1.167     3.729</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city[T.Seattle]</th>       <td>    1.3218</td> <td>    0.719</td> <td>    1.839</td> <td> 0.066</td> <td>   -0.087     2.731</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:             HighSalary   No. Observations:                  413\n",
       "Model:                          Logit   Df Residuals:                      395\n",
       "Method:                           MLE   Df Model:                           17\n",
       "Date:                Mon, 11 Jul 2016   Pseudo R-squ.:                  0.1422\n",
       "Time:                        01:11:18   Log-Likelihood:                -245.26\n",
       "converged:                      False   LL-Null:                       -285.92\n",
       "                                        LLR p-value:                 2.234e-10\n",
       "=========================================================================================\n",
       "                            coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "-----------------------------------------------------------------------------------------\n",
       "Intercept                -1.3218      0.563     -2.349      0.019        -2.425    -0.219\n",
       "city[T.Austin]            1.0341      0.949      1.090      0.276        -0.825     2.893\n",
       "city[T.Boston]            2.0794      0.644      3.230      0.001         0.817     3.341\n",
       "city[T.Chicago]           1.4330      0.654      2.190      0.029         0.151     2.715\n",
       "city[T.Dallas]            0.6286      0.832      0.756      0.450        -1.001     2.259\n",
       "city[T.Denver]           -0.2187      0.849     -0.257      0.797        -1.883     1.446\n",
       "city[T.Houston]         -22.8306   5.85e+04     -0.000      1.000     -1.15e+05  1.15e+05\n",
       "city[T.Los+Angeles]       1.3218      0.695      1.901      0.057        -0.041     2.684\n",
       "city[T.Miami]            -0.2877      1.232     -0.234      0.815        -2.701     2.126\n",
       "city[T.New+York]          0.9886      0.597      1.656      0.098        -0.182     2.159\n",
       "city[T.Palo+Alto]         2.1868      0.703      3.110      0.002         0.809     3.565\n",
       "city[T.Philadelphia]      1.8814      0.842      2.234      0.026         0.230     3.532\n",
       "city[T.Phoenix]         -24.0875   1.34e+05     -0.000      1.000     -2.63e+05  2.63e+05\n",
       "city[T.Pittsburgh]      -22.8306   5.85e+04     -0.000      1.000     -1.15e+05  1.15e+05\n",
       "city[T.Portland]        -15.4028   4282.475     -0.004      0.997     -8408.899  8378.093\n",
       "city[T.San+Diego]         0.9163      0.856      1.070      0.285        -0.762     2.595\n",
       "city[T.San+Francisco]     2.4478      0.653      3.746      0.000         1.167     3.729\n",
       "city[T.Seattle]           1.3218      0.719      1.839      0.066        -0.087     2.731\n",
       "=========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "\n",
    "model = sm.logit(\"HighSalary ~ city\", data=salary_data).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "1ecd7811-d200-44bc-942f-4beb76d2689c"
   },
   "source": [
    "#### Create a few new variables in your dataframe to represent interesting features of a job title.\n",
    "- For example, create a feature that represents whether 'Senior' is in the title \n",
    "- or whether 'Manager' is in the title. \n",
    "- Then build a new Logistic Regression model with these features. Do they add any value? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "b847f46e-1626-4340-86fb-08dea8c31a84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.583474\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arahuja/anaconda/envs/py34/lib/python3.4/site-packages/statsmodels/base/model.py:466: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>HighSalary</td>    <th>  No. Observations:  </th>  <td>   413</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   393</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>    19</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Mon, 11 Jul 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.1572</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>01:11:23</td>     <th>  Log-Likelihood:    </th> <td> -240.97</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>False</td>      <th>  LL-Null:           </th> <td> -285.92</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>3.469e-11</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>               <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>             <td>   -1.3182</td> <td>    0.563</td> <td>   -2.340</td> <td> 0.019</td> <td>   -2.422    -0.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city[T.Austin]</th>        <td>    0.8884</td> <td>    0.959</td> <td>    0.926</td> <td> 0.354</td> <td>   -0.992     2.769</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city[T.Boston]</th>        <td>    1.9411</td> <td>    0.647</td> <td>    3.001</td> <td> 0.003</td> <td>    0.673     3.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city[T.Chicago]</th>       <td>    1.3342</td> <td>    0.657</td> <td>    2.030</td> <td> 0.042</td> <td>    0.046     2.622</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city[T.Dallas]</th>        <td>    0.4513</td> <td>    0.842</td> <td>    0.536</td> <td> 0.592</td> <td>   -1.199     2.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city[T.Denver]</th>        <td>   -0.2104</td> <td>    0.851</td> <td>   -0.247</td> <td> 0.805</td> <td>   -1.879     1.458</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city[T.Houston]</th>       <td>  -21.6234</td> <td> 2.74e+04</td> <td>   -0.001</td> <td> 0.999</td> <td>-5.36e+04  5.36e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city[T.Los+Angeles]</th>   <td>    1.2439</td> <td>    0.698</td> <td>    1.783</td> <td> 0.075</td> <td>   -0.124     2.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city[T.Miami]</th>         <td>   -0.6919</td> <td>    1.260</td> <td>   -0.549</td> <td> 0.583</td> <td>   -3.162     1.778</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city[T.New+York]</th>      <td>    0.8731</td> <td>    0.599</td> <td>    1.456</td> <td> 0.145</td> <td>   -0.302     2.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city[T.Palo+Alto]</th>     <td>    2.0951</td> <td>    0.706</td> <td>    2.970</td> <td> 0.003</td> <td>    0.712     3.478</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city[T.Philadelphia]</th>  <td>    1.7234</td> <td>    0.850</td> <td>    2.028</td> <td> 0.043</td> <td>    0.057     3.389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city[T.Phoenix]</th>       <td>  -24.0910</td> <td> 1.34e+05</td> <td>   -0.000</td> <td> 1.000</td> <td>-2.63e+05  2.63e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city[T.Pittsburgh]</th>    <td>  -21.8127</td> <td> 3.23e+04</td> <td>   -0.001</td> <td> 0.999</td> <td>-6.33e+04  6.32e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city[T.Portland]</th>      <td>  -16.4545</td> <td> 4423.749</td> <td>   -0.004</td> <td> 0.997</td> <td>-8686.844  8653.935</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city[T.San+Diego]</th>     <td>    0.4993</td> <td>    0.884</td> <td>    0.565</td> <td> 0.572</td> <td>   -1.234     2.232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city[T.San+Francisco]</th> <td>    2.2527</td> <td>    0.658</td> <td>    3.425</td> <td> 0.001</td> <td>    0.964     3.542</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>city[T.Seattle]</th>       <td>    1.2322</td> <td>    0.723</td> <td>    1.705</td> <td> 0.088</td> <td>   -0.184     2.649</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_senior</th>             <td>    0.9833</td> <td>    0.352</td> <td>    2.790</td> <td> 0.005</td> <td>    0.293     1.674</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_manager</th>            <td>   -0.0682</td> <td>    0.463</td> <td>   -0.147</td> <td> 0.883</td> <td>   -0.976     0.840</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:             HighSalary   No. Observations:                  413\n",
       "Model:                          Logit   Df Residuals:                      393\n",
       "Method:                           MLE   Df Model:                           19\n",
       "Date:                Mon, 11 Jul 2016   Pseudo R-squ.:                  0.1572\n",
       "Time:                        01:11:23   Log-Likelihood:                -240.97\n",
       "converged:                      False   LL-Null:                       -285.92\n",
       "                                        LLR p-value:                 3.469e-11\n",
       "=========================================================================================\n",
       "                            coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "-----------------------------------------------------------------------------------------\n",
       "Intercept                -1.3182      0.563     -2.340      0.019        -2.422    -0.214\n",
       "city[T.Austin]            0.8884      0.959      0.926      0.354        -0.992     2.769\n",
       "city[T.Boston]            1.9411      0.647      3.001      0.003         0.673     3.209\n",
       "city[T.Chicago]           1.3342      0.657      2.030      0.042         0.046     2.622\n",
       "city[T.Dallas]            0.4513      0.842      0.536      0.592        -1.199     2.102\n",
       "city[T.Denver]           -0.2104      0.851     -0.247      0.805        -1.879     1.458\n",
       "city[T.Houston]         -21.6234   2.74e+04     -0.001      0.999     -5.36e+04  5.36e+04\n",
       "city[T.Los+Angeles]       1.2439      0.698      1.783      0.075        -0.124     2.611\n",
       "city[T.Miami]            -0.6919      1.260     -0.549      0.583        -3.162     1.778\n",
       "city[T.New+York]          0.8731      0.599      1.456      0.145        -0.302     2.048\n",
       "city[T.Palo+Alto]         2.0951      0.706      2.970      0.003         0.712     3.478\n",
       "city[T.Philadelphia]      1.7234      0.850      2.028      0.043         0.057     3.389\n",
       "city[T.Phoenix]         -24.0910   1.34e+05     -0.000      1.000     -2.63e+05  2.63e+05\n",
       "city[T.Pittsburgh]      -21.8127   3.23e+04     -0.001      0.999     -6.33e+04  6.32e+04\n",
       "city[T.Portland]        -16.4545   4423.749     -0.004      0.997     -8686.844  8653.935\n",
       "city[T.San+Diego]         0.4993      0.884      0.565      0.572        -1.234     2.232\n",
       "city[T.San+Francisco]     2.2527      0.658      3.425      0.001         0.964     3.542\n",
       "city[T.Seattle]           1.2322      0.723      1.705      0.088        -0.184     2.649\n",
       "is_senior                 0.9833      0.352      2.790      0.005         0.293     1.674\n",
       "is_manager               -0.0682      0.463     -0.147      0.883        -0.976     0.840\n",
       "=========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data['is_senior'] = salary_data['title'].str.contains('Senior').astype(int)\n",
    "salary_data['is_director'] = salary_data['title'].str.contains('Director').astype(int)\n",
    "salary_data['is_manager'] = salary_data['title'].str.contains('Manager').astype(int)\n",
    "\n",
    "model = sm.logit(\"HighSalary ~ city + is_senior + is_manager\", data=salary_data).fit()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "7ca5cfdd-958c-4199-aafa-3d3f6c5ba3c4"
   },
   "source": [
    "#### Rebuild this model with scikit-learn.\n",
    "- You can either create the dummy features manually or use the `dmatrix` function from `patsy`\n",
    "- Remember to scale the feature variables as well!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "c75a97f1-f30c-48b3-97cb-eaf7d525c734"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(penalty = 'l2', C=0.1)\n",
    "\n",
    "from patsy import dmatrix\n",
    "X = dmatrix(\"city + is_senior + is_manager + 0\", data=salary_data) # Remember the + 0  to remove the Intercept term\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y = salary_data['HighSalary']\n",
    "\n",
    "model.fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "1e6c6902-2b4a-49f0-b4c7-935a26577d22"
   },
   "source": [
    "#### Use cross-validation in scikit-learn to evaluate the model above. \n",
    "- Evaluate the accuracy, AUC, precision and recall of the model. \n",
    "- Discuss the differences and explain when you want a high-recall or a high-precision model in this scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "3667427c-6534-4dcd-8770-f492b0e3a39e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.532740928806 0.0166458939697\n",
      "precision 0.519592055824 0.0302787005393\n",
      "recall 0.252525252525 0.0894951775084\n",
      "roc_auc 0.513385023948 0.0713438440657\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "for metric in ['accuracy', 'precision', 'recall', 'roc_auc']:\n",
    "    scores = cross_val_score(model, X_scaled, y, cv=3, scoring=metric)\n",
    "    print(metric, scores.mean(), scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "4263b1c0-bfde-42bf-ab45-71c7cd798835"
   },
   "source": [
    "#### Compare L1 and L2 regularization for this logistic regression model. What effect does this have on the coefficients learned?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "2e7d6a29-a515-468a-9953-9d73a0f81de0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.547233682429 0.0242551603251\n",
      "precision 0.59012345679 0.105683627452\n",
      "recall 0.247474747475 0.0936729140959\n",
      "roc_auc 0.475290364522 0.0560828230827\n",
      "\n",
      "accuracy 0.532740928806 0.0166458939697\n",
      "precision 0.514653784219 0.0366329563847\n",
      "recall 0.222222222222 0.114947542189\n",
      "roc_auc 0.513385023948 0.0713438440657\n",
      "\n",
      "accuracy 0.561726436052 0.00770585416491\n",
      "precision 0.635978835979 0.0735582950137\n",
      "recall 0.247474747475 0.0936729140959\n",
      "roc_auc 0.534037558685 0.00682020167896\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(penalty = 'l1', C=1.0)\n",
    "\n",
    "for metric in ['accuracy', 'precision', 'recall', 'roc_auc']:\n",
    "    scores = cross_val_score(model, X_scaled, y, cv=3, scoring=metric)\n",
    "    print(metric, scores.mean(), scores.std())\n",
    "\n",
    "print()    \n",
    "model = LogisticRegression(penalty = 'l2', C=1.0)\n",
    "\n",
    "for metric in ['accuracy', 'precision', 'recall', 'roc_auc']:\n",
    "    scores = cross_val_score(model, X_scaled, y, cv=3, scoring=metric)\n",
    "    print(metric, scores.mean(), scores.std())\n",
    "    \n",
    "print()\n",
    "model = LogisticRegression(penalty = 'l1', C=0.1)\n",
    "\n",
    "for metric in ['accuracy', 'precision', 'recall', 'roc_auc']:\n",
    "    scores = cross_val_score(model, X_scaled, y, cv=3, scoring=metric)\n",
    "    print(metric, scores.mean(), scores.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "32d908a3-89d2-474c-a7f0-199bfae6da7e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.309884</td>\n",
       "      <td>city[San+Francisco]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.205423</td>\n",
       "      <td>city[Boston]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.182683</td>\n",
       "      <td>is_senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.165924</td>\n",
       "      <td>city[Palo+Alto]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.020842</td>\n",
       "      <td>city[Philadelphia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000772</td>\n",
       "      <td>city[Chicago]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>city[Austin]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>city[Seattle]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>city[San+Diego]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>is_manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>city[New+York]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>city[Los+Angeles]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>city[Dallas]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.014570</td>\n",
       "      <td>city[Portland]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.055204</td>\n",
       "      <td>city[Miami]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.099641</td>\n",
       "      <td>city[Atlanta]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.119223</td>\n",
       "      <td>city[Denver]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.129556</td>\n",
       "      <td>city[Phoenix]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.201618</td>\n",
       "      <td>city[Pittsburgh]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.211097</td>\n",
       "      <td>city[Houston]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        coef             features\n",
       "16  0.309884  city[San+Francisco]\n",
       "2   0.205423         city[Boston]\n",
       "18  0.182683            is_senior\n",
       "10  0.165924      city[Palo+Alto]\n",
       "11  0.020842   city[Philadelphia]\n",
       "3   0.000772        city[Chicago]\n",
       "1   0.000000         city[Austin]\n",
       "17  0.000000        city[Seattle]\n",
       "15  0.000000      city[San+Diego]\n",
       "19  0.000000           is_manager\n",
       "9   0.000000       city[New+York]\n",
       "7   0.000000    city[Los+Angeles]\n",
       "4   0.000000         city[Dallas]\n",
       "14 -0.014570       city[Portland]\n",
       "8  -0.055204          city[Miami]\n",
       "0  -0.099641        city[Atlanta]\n",
       "5  -0.119223         city[Denver]\n",
       "12 -0.129556        city[Phoenix]\n",
       "13 -0.201618     city[Pittsburgh]\n",
       "6  -0.211097        city[Houston]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_scaled, y)\n",
    "\n",
    "df = pd.DataFrame({'features' : X.design_info.column_names, 'coef': model.coef_[0,:]})\n",
    "df.sort_values('coef', ascending=False, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": true,
    "id": "82f16f60-6c8b-4376-b3ec-b8ec61a0cde7"
   },
   "source": [
    "#### Continue to incorporate other text features from the title or summary that you believe will predict the salary and examine their coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "f38c1eab-6e5f-4dcb-92bc-e8ba524edf1c"
   },
   "source": [
    "#### Take ~100 scraped entries with salaries. Convert them to use with your model and predict the salary - which entries have the highest predicted salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "14068f8f-f3f9-4cbe-a163-e5c2feeae991"
   },
   "source": [
    "### BONUS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "3f242a55-4518-4c95-ae90-6888c68077d3"
   },
   "source": [
    "#### Bonus: Use Count Vectorizer from scikit-learn to create features from the text summaries. \n",
    "- Examine using count or binary features in the model\n",
    "- Re-evaluate the logistic regression model using these. Does this improve the model performance? \n",
    "- What text features are most valuable? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "757205dc-443d-4754-9d23-e591e0921c02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.658485842237 0.0436273832017\n",
      "precision 0.694949494949 0.0768739296583\n",
      "recall 0.525252525253 0.0142849854785\n",
      "roc_auc 0.722178257536 0.0352551146836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arahuja/anaconda/envs/py34/lib/python3.4/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/arahuja/anaconda/envs/py34/lib/python3.4/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(salary_data.summary)\n",
    "X_scaled = scaler.fit_transform(X.toarray())\n",
    "\n",
    "for metric in ['accuracy', 'precision', 'recall', 'roc_auc']:\n",
    "    scores = cross_val_score(model, X_scaled, y, cv=3, scoring=metric)\n",
    "    print(metric, scores.mean(), scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "f44df3c1-cf82-4271-8660-fdd0052097b6"
   },
   "outputs": [],
   "source": [
    "model.fit(X_scaled, y)\n",
    "\n",
    "df = pd.DataFrame({'features' : vectorizer.get_feature_names(), 'coef': model.coef_[0,:]})\n",
    "df.sort_values('coef', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "e182bbe4-2a72-4e75-a3e8-c117688cb8a6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>0.276842</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>0.229212</td>\n",
       "      <td>scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>0.226615</td>\n",
       "      <td>leading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>0.223824</td>\n",
       "      <td>models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>0.223101</td>\n",
       "      <td>learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          coef   features\n",
       "1454  0.276842    science\n",
       "1457  0.229212  scientist\n",
       "921   0.226615    leading\n",
       "1047  0.223824     models\n",
       "923   0.223101   learning"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "a15ef8ea-3130-4c08-a165-ac34d2a8d829"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>-0.079242</td>\n",
       "      <td>provide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>-0.108528</td>\n",
       "      <td>project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>-0.113453</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>-0.137474</td>\n",
       "      <td>related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>-0.160300</td>\n",
       "      <td>research</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          coef  features\n",
       "1318 -0.079242   provide\n",
       "1304 -0.108528   project\n",
       "104  -0.113453       and\n",
       "1383 -0.137474   related\n",
       "1408 -0.160300  research"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "ba66cb98-4567-4c32-bd61-02aea0951678"
   },
   "source": [
    "#### Re-test L1 and L2 regularization. You can use LogisticRegressionCV to find the optimal reguarlization parameters. \n",
    "- Re-test what text features are most valuable.  \n",
    "- How do L1 and L2 change the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "b8a13337-0cde-4117-a928-ffae14661453"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.702175676152 0.00102229902425\n",
      "precision 0.723376515299 0.031149832171\n",
      "recall 0.621212121212 0.0566917785875\n",
      "roc_auc 0.7708679123 0.0210257205031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arahuja/anaconda/envs/py34/lib/python3.4/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/arahuja/anaconda/envs/py34/lib/python3.4/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "model = LogisticRegressionCV()\n",
    "\n",
    "X = vectorizer.fit_transform(salary_data.summary)\n",
    "X_scaled = scaler.fit_transform(X.toarray())\n",
    "\n",
    "for metric in ['accuracy', 'precision', 'recall', 'roc_auc']:\n",
    "    scores = cross_val_score(model, X_scaled, y, cv=3, scoring=metric)\n",
    "    print(metric, scores.mean(), scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "936cd752-6b3f-450f-bfb6-1659c6e71539"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
