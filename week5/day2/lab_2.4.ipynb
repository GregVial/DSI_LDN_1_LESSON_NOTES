{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Pipeline Lab 2 - fitting logistic regression model\n",
    "\n",
    "In the previous lab we have constructed a processing pipeline using `sklearn` for the titanic dataset. At this point you should have a set of features ready for consumption by a Logistic Regression model.\n",
    "\n",
    "In this lab we will use the pre-processing pipeline you have created and combine it with a classification model. This demonstrates how the workflow can be separated out into distinct tasks.\n",
    "\n",
    "Again we have imported this titanic data into our PostgreSQL instance that you can find connecting here:\n",
    "\n",
    "    psql -h dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com -p 5432 -U dsi_student titanic\n",
    "    password: gastudents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all let's load a few things:\n",
    "\n",
    "- standard packages\n",
    "- the training set from lab 2.3\n",
    "- the union we have saved in lab 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('postgresql://dsi_student:gastudents@dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com/titanic')\n",
    "df = pd.read_sql('SELECT * FROM train', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is how we get back our pickled union object\n",
    "\n",
    "import gzip\n",
    "import dill\n",
    "\n",
    "with gzip.open('union.dill.gz') as fin:\n",
    "    union = dill.load(fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's create the training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df[[u'Pclass', u'Sex', u'Age', u'SibSp', u'Parch', u'Fare', u'Embarked']]\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Pipeline\n",
    "\n",
    "Combine the union you have created in the previous lab with a LogisticRegression instance. Notice that a `sklearn.pipeline` can have an arbitrary number of transformation steps, but only one, optional, estimator step as the last one in the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "pipe = make_pipeline(union,LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train the model\n",
    "Use `X_train` and `y_train` to fit the model.\n",
    "Use `X_test` to generate predicted values for the target variable and save those in a new variable called `y_pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "pipe.fit(X_train,y_train)\n",
    "y_pred = pipe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = y_pred[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate the model accuracy\n",
    "\n",
    "1. Use the `confusion_matrix` and `classification_report` functions to assess the quality of the model.\n",
    "- Embed the results of the `confusion_matrix` in a Pandas dataframe with appropriate column names and index, so that it's easier to understand what kind of error the model is incurring into.\n",
    "- Are there more false positives or false negatives? (remember we are trying to predict survival)\n",
    "- How does that relate to what the `classification_report` is showing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_Died</th>\n",
       "      <th>predicted_Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Died</th>\n",
       "      <td>151</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>36</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predicted_Died  predicted_Survived\n",
       "Died                 151                  24\n",
       "Survived              36                  84"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conmat = np.array(confusion_matrix(y_test, y_pred))\n",
    "confusion = pd.DataFrame(conmat, index=['Died', 'Survived'],columns=['predicted_Died', 'predicted_Survived'])\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.86      0.83       175\n",
      "          1       0.78      0.70      0.74       120\n",
      "\n",
      "avg / total       0.80      0.80      0.79       295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Improving the model\n",
    "\n",
    "Can we improve the accuracy of the model?\n",
    "\n",
    "One way to do this is to use tune the parameters controlling it.\n",
    "\n",
    "You can get a list of all the model parameters using `model.get_params().keys()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'featureunion': FeatureUnion(n_jobs=1,\n",
       "        transformer_list=[('pipeline-1', Pipeline(steps=[('columnselector', ColumnSelector(columns='Age')), ('imputer', Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)), ('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True))])), ('pipeline-2', Pipeline(step...r(columns='Fare')), ('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True))]))],\n",
       "        transformer_weights=None),\n",
       " 'featureunion__n_jobs': 1,\n",
       " 'featureunion__pipeline-1': Pipeline(steps=[('columnselector', ColumnSelector(columns='Age')), ('imputer', Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)), ('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True))]),\n",
       " 'featureunion__pipeline-1__columnselector': ColumnSelector(columns='Age'),\n",
       " 'featureunion__pipeline-1__columnselector__columns': 'Age',\n",
       " 'featureunion__pipeline-1__imputer': Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0),\n",
       " 'featureunion__pipeline-1__imputer__axis': 0,\n",
       " 'featureunion__pipeline-1__imputer__copy': True,\n",
       " 'featureunion__pipeline-1__imputer__missing_values': 'NaN',\n",
       " 'featureunion__pipeline-1__imputer__strategy': 'mean',\n",
       " 'featureunion__pipeline-1__imputer__verbose': 0,\n",
       " 'featureunion__pipeline-1__standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'featureunion__pipeline-1__standardscaler__copy': True,\n",
       " 'featureunion__pipeline-1__standardscaler__with_mean': True,\n",
       " 'featureunion__pipeline-1__standardscaler__with_std': True,\n",
       " 'featureunion__pipeline-1__steps': [('columnselector',\n",
       "   ColumnSelector(columns='Age')),\n",
       "  ('imputer',\n",
       "   Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)),\n",
       "  ('standardscaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       " 'featureunion__pipeline-2': Pipeline(steps=[('getdummiestransformer', GetDummiesTransformer(columns=['Embarked']))]),\n",
       " 'featureunion__pipeline-2__getdummiestransformer': GetDummiesTransformer(columns=['Embarked']),\n",
       " 'featureunion__pipeline-2__getdummiestransformer__columns': ['Embarked'],\n",
       " 'featureunion__pipeline-2__steps': [('getdummiestransformer',\n",
       "   GetDummiesTransformer(columns=['Embarked']))],\n",
       " 'featureunion__pipeline-3': Pipeline(steps=[('getdummiestransformer', GetDummiesTransformer(columns=['Pclass']))]),\n",
       " 'featureunion__pipeline-3__getdummiestransformer': GetDummiesTransformer(columns=['Pclass']),\n",
       " 'featureunion__pipeline-3__getdummiestransformer__columns': ['Pclass'],\n",
       " 'featureunion__pipeline-3__steps': [('getdummiestransformer',\n",
       "   GetDummiesTransformer(columns=['Pclass']))],\n",
       " 'featureunion__pipeline-4': Pipeline(steps=[('columnselector', ColumnSelector(columns='Sex')), ('booleantransformer', BooleanTransformer(baseValue='female'))]),\n",
       " 'featureunion__pipeline-4__booleantransformer': BooleanTransformer(baseValue='female'),\n",
       " 'featureunion__pipeline-4__booleantransformer__baseValue': 'female',\n",
       " 'featureunion__pipeline-4__columnselector': ColumnSelector(columns='Sex'),\n",
       " 'featureunion__pipeline-4__columnselector__columns': 'Sex',\n",
       " 'featureunion__pipeline-4__steps': [('columnselector',\n",
       "   ColumnSelector(columns='Sex')),\n",
       "  ('booleantransformer', BooleanTransformer(baseValue='female'))],\n",
       " 'featureunion__pipeline-5': Pipeline(steps=[('columnselector', ColumnSelector(columns='Fare')), ('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True))]),\n",
       " 'featureunion__pipeline-5__columnselector': ColumnSelector(columns='Fare'),\n",
       " 'featureunion__pipeline-5__columnselector__columns': 'Fare',\n",
       " 'featureunion__pipeline-5__standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'featureunion__pipeline-5__standardscaler__copy': True,\n",
       " 'featureunion__pipeline-5__standardscaler__with_mean': True,\n",
       " 'featureunion__pipeline-5__standardscaler__with_std': True,\n",
       " 'featureunion__pipeline-5__steps': [('columnselector',\n",
       "   ColumnSelector(columns='Fare')),\n",
       "  ('standardscaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       " 'featureunion__transformer_list': [('pipeline-1',\n",
       "   Pipeline(steps=[('columnselector', ColumnSelector(columns='Age')), ('imputer', Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)), ('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True))])),\n",
       "  ('pipeline-2',\n",
       "   Pipeline(steps=[('getdummiestransformer', GetDummiesTransformer(columns=['Embarked']))])),\n",
       "  ('pipeline-3',\n",
       "   Pipeline(steps=[('getdummiestransformer', GetDummiesTransformer(columns=['Pclass']))])),\n",
       "  ('pipeline-4',\n",
       "   Pipeline(steps=[('columnselector', ColumnSelector(columns='Sex')), ('booleantransformer', BooleanTransformer(baseValue='female'))])),\n",
       "  ('pipeline-5',\n",
       "   Pipeline(steps=[('columnselector', ColumnSelector(columns='Fare')), ('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True))]))],\n",
       " 'featureunion__transformer_weights': None,\n",
       " 'logisticregression': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False),\n",
       " 'logisticregression__C': 1.0,\n",
       " 'logisticregression__class_weight': None,\n",
       " 'logisticregression__dual': False,\n",
       " 'logisticregression__fit_intercept': True,\n",
       " 'logisticregression__intercept_scaling': 1,\n",
       " 'logisticregression__max_iter': 100,\n",
       " 'logisticregression__multi_class': 'ovr',\n",
       " 'logisticregression__n_jobs': 1,\n",
       " 'logisticregression__penalty': 'l2',\n",
       " 'logisticregression__random_state': None,\n",
       " 'logisticregression__solver': 'liblinear',\n",
       " 'logisticregression__tol': 0.0001,\n",
       " 'logisticregression__verbose': 0,\n",
       " 'logisticregression__warm_start': False,\n",
       " 'steps': [('featureunion', FeatureUnion(n_jobs=1,\n",
       "          transformer_list=[('pipeline-1', Pipeline(steps=[('columnselector', ColumnSelector(columns='Age')), ('imputer', Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)), ('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True))])), ('pipeline-2', Pipeline(step...r(columns='Fare')), ('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True))]))],\n",
       "          transformer_weights=None)),\n",
       "  ('logisticregression',\n",
       "   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "             penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "             verbose=0, warm_start=False))]}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can systematically probe parameter combinations by using the `GridSearchCV` function. Implement a new classifier that searches the best parameter combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression__C': 100}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You use a double underscore __ to identify the label for the hyperparameter (e.g. C) that you wish to gridsearch,\n",
    "# after the name of the classifier as input to the pipeline. So for example param_grid={\"LogisticRegression__C\":[...]}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = dict(logisticregression__C = [.1,10,100,1000])\n",
    "grid_search = GridSearchCV(pipe, param_grid=params, scoring=\"accuracy\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Assess the tuned model\n",
    "\n",
    "A tuned grid search model stores the best parameter combination and the best estimator as attributes.\n",
    "\n",
    "1. Use these to generate a new prediction vector `y_pred`.\n",
    "- Use the `confusion matrix` and `classification_report` to assess the accuracy of the new model.\n",
    "- How does the new model compare with the old one?\n",
    "- What else could you do to improve the accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.85      0.83       549\n",
      "          1       0.74      0.68      0.71       342\n",
      "\n",
      "avg / total       0.78      0.79      0.78       891\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_Died</th>\n",
       "      <th>predicted_Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Died</th>\n",
       "      <td>468</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>109</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predicted_Died  predicted_Survived\n",
       "Died                 468                  81\n",
       "Survived             109                 233"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.set_params(logisticregression__C = 100)\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.transform(X)\n",
    "y_pred = y_pred[:,1]\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y, y_pred))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conmat = np.array(confusion_matrix(y, y_pred))\n",
    "confusion = pd.DataFrame(conmat, index=['Died', 'Survived'],columns=['predicted_Died', 'predicted_Survived'])\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "What would happen if we used a different scoring function? Would our results change?\n",
    "Choose one or two classification metrics from the [sklearn provided metrics](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) and repeat the grid_search. Do your result change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
